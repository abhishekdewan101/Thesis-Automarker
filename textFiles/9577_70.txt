 
 
Abstract 
The project is divided into 2 parts. 
For the implement part, it aims to rebuild a honey bee olfactory system model which 
can simulate some basic cognitive behaviors found among the activities of honey bees. 
And then, the model is used to verify the relationship between the lateral inhibition 
which is a type of interaction between local interneurons in olfactory system and the 
cognitive behaviors. By the generalization, overshadowing experiments, the effect of 
lateral inhibition on the behaviors are identified. After compared with previous data, 
the reliability of the program based on this theory is proved. 
For the research part, the parameter of time constant is researched and the different 
time constant is chosen to measure the effect on these behaviors. The data shows that 
the increase of time constant contributes to the strong generalization, which means 
time constant may disturb the neurons’ judge on the right discrimination from the 
odorant mixture.  
Finally, how to improve the model is described, what is more, the output of PNs in the 
built model will be taken as the further research object in the future to verify the 
classification in the more complex olfactory organization Mushroom Body. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Table of Contents 
Abstract ..................................................................................................................... 2 
Acknowledgement..................................................................................................... 3 
1 Introduction ............................................................................................................ 1 
1.1 Aims and Objectives .................................................................................... 7 
1.2 Organization ................................................................................................ 7 
2. Background ........................................................................................................... 9 
2.1 Neuron ......................................................................................................... 9 
2.2 Olfactory System ....................................................................................... 10 
2.2.1 VUMmx1 ........................................................................................ 13 
2.3 Learning about odorant .............................................................................. 14 
2.3.1 Generalization ................................................................................. 14 
2.3.2 Overshadowing ............................................................................... 15 
2.3.3 Blocking........................................................................................... 15 
2.4 Model Architecture .................................................................................... 16 
2.4.1 Odor processing .............................................................................. 17 
2.4.2 Associative learning ......................................................................... 18 
2.4.3 Unsupervised Hebb Rule ................................................................. 20 
2.4.4 Integrate-and-fire models ................................................................ 22 
2.4.5 Model parameter ............................................................................ 24 
2.4.6 The process of simulation ................................................................ 24 
3 Project Design ...................................................................................................... 27 
3.1 Input and Output ........................................................................................ 27 
3.2 module design ............................................................................................ 28 
3.2.1 Gaussian Module ............................................................................. 28 
3.2.2 The quasi-linear function ................................................................. 29 
3.2.3 Reception Cell ................................................................................. 29 
3.2.4 Local Interneuron ............................................................................ 30 
3.2.5 Projection Neuron ........................................................................... 30 
3.2.6 Lateral inhibition ............................................................................. 30 
3.2.7 The relationship of RC, LN and PN ................................................. 31 
3.2.8 Associative Learning ....................................................................... 31 
3.2.9 VUM output .................................................................................... 32 
3.3 GUI Design................................................................................................ 33 
4 Experiments and Results....................................................................................... 36 
4.1 LN, PN and lateral inhibition ..................................................................... 36 
4.2 Learning .................................................................................................... 39 
4.3 Generalization ............................................................................................ 42 
4.4 Overshadowing .......................................................................................... 44 
4.5 time constant .............................................................................................. 47 
4.6 Summary ................................................................................................... 51 
 
 
5 Future Work ......................................................................................................... 52 
5.1 Improvement of Odor Processing ........................................................... 52 
5.2 Open Parameter ...................................................................................... 52 
5.3 Classification Method ............................................................................. 52 
6 Conclusion ........................................................................................................... 55 
7. References ........................................................................................................... 57 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
1 Introduction 
It is believed that the studies on insect brains can disclose the certain cognitive abilities which 
were thought only belonged to vertebrates. On the one hand, the discovery of cognitive 
behavior in insects contradicts the statement that there are close relationship between brain size 
and neuronal circuits. On the other hand, the progress of understanding how it works with 
insect’s neurons may help us do better researches on human’s brain structure. 
 
I am interested in exploring the neural network in brain of honey bee. It is well-known that 
there lie various kinds of associative learning involved in color and odor classification. Behind 
these magic cognitive abilities, there must be special communications in neural network. 
In this case, I will set up and implement a model of cognition based on Linster et al.’s idea [1] to 
simulate the structure of honey bee olfactory system to analyze how honey bee can separate 
single odor from odor mixtures and the nature behind the phenomenon such as overshadowing 
and blocking, which are proved to occur in honey bee. Then the research on time constant will 
be developed and the effect will be evaluated. 
1.1 Aims and Objectives 
The aims of this project are to set up a neural network model of honeybee’s olfactory 
system and use this model to research on some cognitive behaviors arising from 
neuronal circuits. 
 
There are several stage objectives to meet this aim: 
1. Design an artificial neural network model to simulate the neurosis in honey bee 
brain. 
2. Adjust and choose the most suitable open parameters. 
3. Analyze the output data and identify the cognitive behavior phenomenon. 
4. Compare the different results when adopting different hebbian learning rules. 
5. Evaluate the effect of time constant and research on the relationship between time 
constant and cognitive behavior. 
1.2 Organization 
The organization of the essay is as following: 
Chapter 2: Background. In this part, the background knowledge for this project is 
introduced. This includes the cognitive behaviors of honey bee such as generalization 
and overshadowing, and some algorithms involved in the experiment such as 
associative learning and integrate-and-fire mode.  
Chapter 3: Project design. The function of each part of the model is described and the 
GUI of program is shown. The designing parameters and the main algorithms are 
 
 
discussed and chosen.  
Chapter 4: Experiments and results. In this Chapter, several experiments about the 
cognitive behaviors are done and the results will be analyzed.  
Chapter 5: Future work. In this part, how to improve the performance of the model is 
described and another classification method is presented. In the future, the model will 
be improved and the experiment results will be tested and compared with the present 
ones. 
Chapter 6: Conclusion. The content of the essay will be summarized in general. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
2. Background 
“It is certain that there may be extraordinary activity with an extremely small absolute 
mass of nervous matter; thus the wonderfully diversified instincts, mental powers, and 
affections of ants are notorious, yet their cerebral ganglia are not so large as the quarter 
of a small pin’s head.”[2] 
                                                               --- Charles Darwin 
 
It is amazing that many insects have complex cognitive behaviors. A honeybee worker 
is recorded having nearly 60 behavior types[3]. All these behaviors are conducted in a 
tiny brain. Scientists have found that most insects with cognitive features such as 
numerosity, attention and catergorisation-like processes only need limited neuron 
numbers[3]. A honey bee, whose brain has a volume of ~1 mm
3
 and fewer than 1 
million neurons, shows good cognitive capacity[4]. It is said that although the 
honeybee’s learning speed is slower than human infants, it is faster than all vertebrates 
that have been studied[3]. Also, it is shown from Changizi’s collecting data among 
animalia, a honey bee can perform more kinds of behaviours than a North American 
moose does[3]. A mature honeybee worker has 59 distinct behavior types from Lars 
and Jeremy’s survey, which include packing pollen, round dance, cell cleaning and so 
on[3].  
 
Although the small amount of neurons, a honeybee can conduct rich activities. There 
must be special connectivity between neurons. Artificial neural network analyses show 
that the minimum number of neurons necessary to complete various complex cognitive 
tasks is particularly small, for instance, conducting a simple visual categorization task 
only needs a network of seven sensory neurons, five interneurons, and motor 
neurons[5]. 
 
Exploring the concrete connection and interaction of neurons in the insect neural 
network contributes a lot to disclose the insect behavior and know more about the 
human brain. This project will do the research on the cognitive behavior in honeybee 
using the machine learning based technique. The first part introduces the background of 
honeybee olfactory system and several cognitive behaviors: generalization, blocking 
and overshadowing. My task is to implement the cognitive model on the java platform, 
so the second part introduces this model proposed by Linster and Smith[1]. In order to 
do the further research on the higher odor structure, the hebbian learning, Pavlovian 
classic conditioning and some relevant models are introduced. Their theories are 
crucial for the research in the higher olfactory neurons.   
2.1 Neuron 
Scientists point out that neuron is the single most important concept in brain study. It 
 
 
is special because it is the only tool to transmit electrical signals over long distance. 
The behavior of the organism can be divided into a great number of activities in form 
of neuronal circuits in neurons.  
 
According to Eugene, a common neuron receives over 10,000 neurons inputs through 
the contacts on synapses, these inputs can alter the neural membrane potential by 
electrical currents. The great PSPs (postsynaptic potentials) produced by large 
currents can be amplified by the channels sensitive to voltage and contribute to the 
occurrence of spike. And these spikes are the important communicators for the 
connection of neurons. Neurons could not spike automatically, except that they are 
inspired by the incoming fires from other neurons[6] 
 
When the postsynaptic potentials in a single neuron are reached a certain voltage 
figure which is called the firing threshold, it fires and resets membrane potential.  
  
Figure 2.1: The concept of a firing threshold adopted from[4]. 
2.2 Olfactory System 
Odor mixtures are distributed in natural environment in time and space, the olfactory 
system are intelligent enough to choose the essential odor signals out of noisy 
environment. Olfactory system contains a great many neural circuit elements which are 
regarded as perform essential functions and feedback and feed forward interactions 
among these structures[7]. 
 
The Figure 2.2 shows the main structure which process odors in an insect’s olfactory 
system. 
 
 
Figure 2.2: the main olfactory system in insect brain adopted from [8] 
Insects such as honey bee have three essential odor-classification processing stages: 
The antenna, the antenna lobe(AL) and the mushroom body(MB). 
 
According to Linster and Smith[1], there is great similarity between the insect’s 
antennal lobe and vertebrate olfactory bulb in the first synaptic processing of incoming 
signals from primary receptor cell axons.  
 
The antennal lobe acts a central part for odor classification. It is in charge of odor 
coding and short-term memory. The neural activity involved in the AL is highly 
organized in both time and space. Honeybees possess about 160 glomeruli[9], which is 
the arrangement of neural clusters and contributes to the spatial order. In every 
glomeruli, 3-5 projection neurons(PN) pass olfactory information to higher processing 
areas such as the mushroom bodies. 
 
Mushroom bodies are crucial for odor conditioning, they are lobed neuropils that 
playing a key role in olfactory learning and memory. It is the higher odor-processing 
structure in olfactory system. According to Huerta et al., “the AL performs some 
preprocessing of the data to feed an adequate representation of it into the area of the 
insect brain that is responsible for learning odor conditioning, the MB”.[10] 
 
                 Figure 2.3: the structural organization adopted from [10] 
R. Huerta et al. proposed a model is divided into two stages: a nonlinear 
 
 
transformation from AL to the MB and a classification in the MB lobes[46]. They 
didn’t address the temporal code in odor classification, though it plays a role in 
behavior. However, the research in the Mushroom body is important, and this part will 
introduce their classification idea, which will contribute a lot to my study. 
 
Every receptor cell in the antenna expresses one kind of receptor, what is more, all 
olfactory receptor cells presenting the same receptor connect to the same glomerulus in 
the antennal lobe (AL)[11].There will be spatial code in the glomeruli derived from the 
encoded architecture[12].Within the layer of antennal lobe, sensory cells synapse onto 
output neurons carry information out of the first layer for processing in other neuropils. 
 
The big number of antennal lobe neurons relay inhibition in themselves, while a few 
projection neurons pass information to other neuropils[13][14]. 
 
Because the same kinds of excitatory and inhibitory transmission conducted during 
different animal lineages though the special transmitters and elements are different, 
independent circuitry can perform quite similar or the same functions[1]. 
 
In honeybees, olfactory reward conditioning is enhanced by the biogenic amine 
octopamine. VUM neurons discovered have great effect on appetitive learning, 
showing ling-lasting excitation to the stimulation of sucrose. VUMma1 neuron, as one 
of these neurons, plays a more concrete role. It adjusts the reinforcing function of 
rewards during olfactory conditioning, since its depolarization substitutes the reward in 
olfactory conditioning[15]. This effect simulates a basic property of 
proboscis-extension response conditioning.  
 
Figure 2.4: the similar between VUMmx1 response and sucrose stimuli adopted from 
[15] 
 
 
2.2.1 VUMmx1 
It is said that animals have the capacity to connect a neutral stimulus with an 
unconditioned stimulus which contributes a lot to associative learning in classical 
conditioning stage[16][17][18][19]. Consequently, information extracted from the 
neuron experienced unconditioned stimulus stage is demanded for grasping the global 
features of conditioning. Hammer had identified an interneuron which is called 
VUMmx1 that mediating the unconditioned stimulus during the associative learning. 
This special neuron pointed out has particular response features and unique 
morphology. Its response can last about 30 seconds which outlasts the unconditioned 
stimulus.[20] He also found that there are certain similarities of activity between the 
olfactory system and VUMmx1. The experiment of observing the VUMmx1’s activity 
verifies his hypothesis about the close relationship between the associative strength of 
odors and the increase of the olfactory input to VUMmx1. 
The Figure below shows that honey bees connect on kind of odor CS
+
 as an indicator, 
after the differential conditioning, the response of VUMmx1 to the CS
+
 is intensively 
high compared with the response to CS
-
.[20] 
Figure 2.5: the response of VUMmx1 is in line with the odorant stimulation                   
adopted from[20] 
 
It stimulates the glomeruli in the antennal lobe and also the mushroom bodies. The 
model to be implemented involves two key concepts which are overshadowing and 
blocking, which by now are the essential discovery in honeybee. Next, the explanation 
of both concepts will be presented.     
 
 
2.3 Learning about odorant 
It is well known that flower odorants are usually the complicated mixtures composed of 
hundreds of single odorants, and the mixture can change according to time and location, 
so it is hard for honey bee to identify single odorant among the blend.[21] Dionne and 
Dubin pointed out that many physiological processes can affect animals on 
discriminating single odorants from a blend.[22] The research on sensory physiology 
disclosed the interaction between odor molecules and reception cells can produce 
several effects such as mixture suppression and so on.[23]  
2.3.1 Generalization 
Generalization in the olfactory system has been studied to respond to a pure odorant 
conditioned stimulus[24]. Brian stressed animals including insects make strongly 
response to the conditioned stimulus and less but not as strongly to an odorant similar in 
structure to the conditioned stimulus. The response becomes intensively weaker when 
the architecture of the molecule is altered.[23] 
The neuron activated by the mixture is very different from the result from a simple sum 
of that activated by single odorants from the mixture[25]. Actually, if there is great 
difference between the neural representation for the mixture and ones for the single 
odorants, the generalization from the blend to the single ones will be very weak. The 
figure below shows this particular phenomenon. 
          
     Figure 2.6: the relationship between binary mixture and generalization adopted 
from[23] 
The farer horizontal distance A has from X, the more difference between A and X, the 
weaker of both RA (the response to A) and RX (the response to X). 
 
 
2.3.2 Overshadowing 
Bitterman and Menzel made the experiment to disclose the phenomenon about 
overshadowing[26]. They divided four equal groups of honey bee workers, during the 
single trial, odors were companied by sucrose reinforcement. Two groups were under 
mixture conditioning circumstance and others were under pure circumstance. All 
groups were then tested with the same pure odorant which was not reinforced. The 
diagram shows the probabilities of different groups respond to mixture and pure 
odorant of that mixture. 
 
       Figure 2.7: the overshadowing experiment by Bitterman and Menzel adopted 
from [23] 
Overshadowing shows that when honey bees are conditioned to one stimulus alone, the 
response to that stimulus is stronger than when they are conditioned to a combination of 
this stimulus and another one[27]. The difference in response to an odorant is based on 
the difference between conditioning backgrounds and is a frequent occurrence in 
mixtures[1]. What is more, it can be asymmetric[28], which means one stimulus 
dominates the mixture and have a dominant ability to overshadow the other one in the 
combination. 
2.3.3 Blocking 
Blocking means animals are first conditioned to one stimulus A, and then they are 
conditioned to a mixture which contains A with the same reinforcement, the response 
level to another stimulus is lower when A is preconditioned and the mixture is received 
mixture conditioning.[1]  
 
It is said that the overshadowing is essential as it is not enough to improve the response 
 
 
to a pure odorant with the condition of spatial and temporal pairing of this odorant.  
 
The study of blocking in honey bee is combined with control procedures. There are two 
control groups which are novel group and overshadowing group. The block group was 
first pre-trained and a single odorant A was forward-paired. The novel group is similar 
but novel odorant was forward-paired. And the overshadowing group was not 
pre-trained. All groups were equally trained to the mixture A+B in the second phase. 
Then the test stage came and the responses to single odorant B were tested. The result 
shows that in blocking group the response to odorant B is intensively lower than that in 
novel or overshadowing group. That means acquisition to odorant B is blocked[23]. 
 
A phenomenon is also found that when a single odor is backward-paired or unpaired, 
blocking did not occur [29][30]. Consequently, only forward-pairing contributes to 
blocking.    
  
The first discovery on olfactory blocking in honeybee [30] show that a first odorant 
conditioned blocks learning a second odorant contained in a binary combination with 
the first one. This is contradicted by Gerber and Ullrich [31], who found that when a 
reduction of the intertribal interval and an absence of balance of the odorants are used, 
blocking did not occur. However, Hostler and Smith [32] demonstrated that blocking 
really occurs in the olfactory structure, although is restricted to similar odors. 
2.4 Model Architecture 
The model described here is supposed by Linster and Smith [1] which identifies the 
relationship between lateral inhibition and overshadowing, blocking. 
 
In the model, all the synaptic interactions are in the high synaptic density areas [33]. 
These glomeruli are identifiable morphological neuropilar subnits [1]. The number of 
glomeruli is decreased to 15 and every glomerulus receives input from the same 
receptor cell type. 
 
90% of antennal lobe neurons are constituted by local interneurons(LN), the most of 
which are possibly inhibitory[34]. Receptor cells are hypothesized to synapse primarily 
with LNs. 80% of LNs show a high density of branching in one special glomerulus that 
are called Hetero-LNs[35]. In the model, only the Hetero LNs are involved. And 
similar to the LNs, there are two categories in the projection neurons: Uni-PN and 
Pluri-PN. The previous one has dendrites invading only one glomerulus while the latter 
one is pluri-glomeruluar. In this model, Uni-PNs sum the synaptic activity to one 
glomerulus[1].Three types of activity are integrated by each glomerulus, input from 
one kind of receptor cell, associated inhibitory interneuron providing with local 
inhibition and the lateral inhibition[1]. Release of spontaneous activity of PNs by 
inhibition of presynaptic inhibitory local interneurons is adopted as the neural 
mechanism. Figure 2.8 below shows the model architecture[1], receptor axons(RC) 
 
 
synapse with local interneurons(LN) in GLOM. LN receive connections from RC in a 
single PN, which send lateral inhibitory connections to neighboring glomeruli[1]. 
 
Figure 2.8: neuron interaction and connection adopted from [1] 
2.4.1 Odor processing 
Local interneurons(LNs) which receive the activation from receptor cells inhibit LNs in 
the three golmeruli next to it on the each side. And the intensity of inhibition is graded 
with the increase of the distance. The inhibited LNs then do not impose the inhibition 
on the corresponding PNs, and the PNs increase their spike probability[1]. 
Activated PNs often respond in form of different response patterns during the stimulus. 
Therefore, an across-PN pattern of activation and inhibition marks a special odor 
input[1]. 
 
Figure 3 describes the overlap in the model[1]. Each circle is a glomerulus, O1, O2, O3 
represent odor components, when two glomeruli which two components affect on are 
far from each other, the value of overlap is low. In contrast, when the nearby glomeruli 
are stimulated, the overlap is very large. 
 
 
 
         Figure 2.9: Overlapping in the antennal lobe adopted from [1] 
2.4.2 Associative learning 
Associative learning is a type of unsupervised learning. Unlike supervised learning of 
which the output is a regression during the process and can finally predict a 
classification, in unsupervised learning, all the observations are assumed to be caused 
by latent variables, it is trying to find relationship only with the help of the raw data. 
2.4.2.1 Association  
An association is a relationship between the input and output of a system, when input is 
a pattern, the system will respond with another pattern. When both patterns are linked 
by an association, the input one is referred to as the stimulus. Similarly, the output 
pattern is regarded as the response. 
 
A number of researchers have contributed to the development of associative learning. 
In particular, Tuevo Kohonen, James Anderson and Stephen Grossberg are prominent. 
Anderson and Kohonen independently developed the linear associator network in the 
late 1960s and early 70s. Grossberg introduced nonlinear continuous-time associative 
networks during the same time period[36].      
2.4.2.2 Associative network 
A simple associative network is presented below: 
 
 
 
 
 
 W n Y 
 X 
                     
 B=-0.2 
 A=1 
  
 
 Input              Hard Limit Neuron 
                   Figure 2.10: a simple associative network 
The neuron’s output Y is determined from factor X according to: 
                     Y=F(W*X+A*B)=F(W*X-0.2)              
If X is supposed to be either 0 or 1, presenting a stimulus is absent or present, then Y is 
limited to the same value by the function, which is the response of network. 
X= 
1,             stimulus
0,       no stimulus 
          Y= 
1,        response
0,   no response
       
The presence of an association between X=1 and Y=1 is dictated by the value of W. The 
network will only make response when W>-B. 
2.4.2.3 Pavlovian Classical conditioning  
Classical conditioning is a form of associative learning that was first supposed by Ivan 
Pavlov. The presentations of a neutral stimulus and a stimulus of some significance 
induce the classical conditioning. The neutral stimulus which is any event that does not 
contribute to an overt behavioral response is referred as a conditioned stimulus(CS), 
while presentation of the stimulus evokes an innate is called the unconditioned 
stimulus(CS). [37]  
 
Based on Figure 2.11, the simple model about classical conditioning is presented 
below: 
  X1    w1=1 
                n Y 
  
 
 X2   w2=0       B=-0.2 
 A=1 
 
 Inputs            Hard Limit Neuron 
               Figure 2.11: classic conditioning model 
Y=F(W1*X1+W2*X2+A*B)=F(W1*X1+W2*X2-0.2)    
X1 stands for a mixture of odors o1+o2, X2 presents a type of odor o2, and the inputs of 
∑ 
 
F 
∑ F 
 
 
the unconditioned and conditioned in this network are: 
X1= 
1,       O1 + O2  detected
0, O1 + O2 not detected
      X2= 
1,        O2 detected
0, O2 not detected
  
The network is to associate the compound, but not the O2 with a response separating o1 
from O2. The values of weight during the input stage should satisfy that: X1=1, X2=0. 
The new equation is that: 
Y=F(X1-0.2)             
In this case, the network will respond only if X1=1, not considering whether the odor 
O2 is received or not. 
2.4.3 Unsupervised Hebb Rule 
“Hebbian theory describes a basic mechanism for synaptic plasticity wherein an 
increase in synaptic efficacy arises from the presynaptic cell's repeated and persistent 
stimulation of the postsynaptic cell.”[38] 
 
It has been the fundamental basis for the traditional view that when analyzed from a 
holistic level, engrams are neuronal nets or neural networks.[38] 
 
Hebb’s principle can be regarded as a method to determine the value of weights 
between model neurons. The weight between two neurons increases if the two 
neurons activate at the same time. On the contrary, it reduces if they activate 
separately. There are strong positive weights between the nodes which tend to be 
either positive or negative simultaneous while strong negative weights will arise from 
those to be opposite. 
 
A basic description of Hebbian learning is described as below: 
Wij=XiXj                      
Wij is the weight of the connection between neuron I and j, the X is the input of 
neuron. Weights updated after every training process. 
 
The network in figure 6 can explain the Hebb rule well. If odor compound o1+o2 
stimulus occurs simultaneously with o2 output, the network should strengthen their 
connection. 
The unsupervised Hebb rule increases the weight Wij between a neuron’s input pj and 
output ai: 
                       Wij(q)= Wij(q-1)+kai(q)Pj(q)              
The learning rate k shows how many times a stimulus and response have to occur 
together before an association is made. 
  
Rules that satisfy the condition are called local learning rules. 
 
 
The vector form is as below: 
W(q)=W(q-1)+ka(q)P
T
(q)                 
Learning is conducted in response in the training sequence: 
                            P(1),p(2),…,p(Q)                  
At the each process, the output a is calculated in response to the input p, and the 
weights W are updated. 
 
Previous studies have shown that networks of spiking neurons with biological feature 
can process information fast in the way of encoding information instead of using 
firing probability as the code. In most of neural network structures, there are two ways 
of activation in single unit that are binary variable in the form of 0 or 1 and 
continuous function in the form of any values between 0 and 1. Continuous activation 
functions have close relationship with firing rates of biological neurons[39].  
 
However, S.J.Thorpe proposed that firing rate codes could not be fully used because 
the speed of neural computation is so fast that it could not leave enough time for 
individual units to produce single spike.[40] Some solutions were raised, for example, 
analog-to-delay convertors are applied and the strength of a neuron’s input could 
decide whether a spike occurs. Moreover, the neurons fire in order was used instead 
of computing the latency figures.  
 
Manuel,Simon and Emmanuel had then raised a Hebbian reinforcement learning 
scheme to change the weights of relative neurons to solve the classification problem. 
The core part of their integrate and fire model is described as below[39]: 
 
V(t+1)= 
 1 ? ? V t + f u t          when  V t < ?
                    V0                         when  V t ≥ k
     
 
In this equation, V0 is the neuron ground potential, k is the firing threshold, f is the 
integrating function computing the value of input u(t).  
 
The whole network structure is composed of preprocessing layer and decision neurons. 
The first layer receives the constant activation, after the output of the increasing 
sigmoidal function, the output values of each neurons of the first layer are passed to 
decision neurons. The latency ? is introduced and the expression is[39]: 
?=
k?V0
f(u)
 
The idea of processing the input signals in time order is convenient since it is complex 
to compute ? between the spiking time intervals.  
 
According to Hebbian learning, when the signal passed from neuron is in the firing 
state, the synaptic weights are increased. 
 
 
Here is Manuel et al’s formula[39]: 
Wij(t+1)=Wij(t)+?Xi(t)( ?
kuij t ? k ? Wij (t)
k=t
k=0 )    
Where ? is the learning rate and the value is restricted between 0 and 1. The synaptic 
weights will not be modified when other patterns are involved. The synaptic weights 
are computed according the random recurrence[39]: 
                   Wij(k)=Wij(k-1)+?[?
rj (k)-Wij (k ? 1)] 
rj marks the rank of the activity of neuron j at the step k. ?
r j (k) is the random variable 
whose mean is mi,j and standard deviation ?i,j. Wij(k) is a Markov chain. It is 
important to note that when ? is small, the weights in the stationary law is in almost 
Gaussian form, therefore, the learning rate can adjust the range of fluctuation. 
2.4.4 Integrate-and-fire models 
In 1907, Lapicque researched one of the earliest neuron models[41]. 
The described graph is as below: 
 
          Integrate      Fire        Reset 
 
              ---------------------------------------------------- Vth 
 
             Vm 
 
                Figure 2.12: an integrate-and-fire model 
 
The model is represented in the below equation: 
I(t)=Cm
dVm
dt
 
It is derived from the law of capacitance, which is shown below: 
Q=CV 
The membrane potential increases with time and stops when it reaches the threshold 
Vth. A fire then occurs and the resting potential is recovered. The spiking rate 
increases linearly with the increase of input current. 
The circuit diagram is as below.  
Iin(t) is the input current which is changed with time. 
Ic= Cm
dVm
dt
   and Vm=Vrst when Vm=Vth 
Vrst is reset potential and Vth is the threshold potential. 
 
 
 
                                           Vm 
                              Ic 
       Iin(t)              Cm 
                                                threshold 
                                                
 
                                        output 
                                          
                           
          Figure 2.13: perfect integrate-and-fire current diagram 
 
It is also called perfect integrate-and-fire model, which is not suitable for the practical 
neuronal behavior because it has no time-memorial function.  
After leaky integrate-and-fire model was introduced, this problem is solved.  
The model is described below: 
I(t)-
Vm (t)
Rm
= Cm
dVm (t)
dt
 
The circuit diagram describes the equation above well: 
                                                         Vm 
 Ic IR 
       Iin(t)              Cm                   Rm 
                                                threshold 
                                                
 
                                                     output 
                                          
                           
           Figure 2.14: leaky integrate-and-fire current diagram 
 
Rm is the membrane resistance.  
Iin(t)=Ic+IR=Cm
dVm (t)
dt
+
Vm (t)
Rm
 
After transformation,  
                   RmCm
dVm (t)
dt
+Vm(t)=RmIin(t) 
Where RmCm is membrane time constant and it is expressed below: 
                            ?= RmCm 
Then  
?
dVm (t)
dt
+Vm(t)=RmIin(t) 
When ? is larger than the interval time between the fires of output, the leak could be 
ignored. Oppositely, when ? is much smaller, the input fluctuation decides whether or 
 
 
 
 
not a spike occurs. 
 
It is pointed out that Iin>Ith is a necessity to produce a fire in the cell, where Ith=Vth/Rm. 
Or some change will be leaked out in potential, the spiking frequency is shown 
below[42]: 
 
f(I)= 
 0,                                                         I ≤ Ith
(tref ? Rm Cm log?(1 ?
V th
IRm
))?1,    I > Ith
  
2.4.5 Model parameter 
When it comes to the model of honey bee olfactory system, it is essential to define which 
synapses should be used in Hebbian learning to reproduce the electrophysiological and the 
behavioral data.[1] Linster and Smith introduced an interneuron which contains properties of 
VUMmx1[43]. It receives sucrose-like input and has arborizations in 15 glomeruli. It is also 
pointed out that odor processing in the intrinsic antennal lobe circuitry should not be subject 
to synaptic plasticity. That means only the synapses from or onto VUM can be modified by 
Hebbian learning.[1] 
 
Synaptic plasticity activated by a special stimuli from AL neurons to the VUM ones is a 
necessary. Learning rule 1 will be used to the simulations between VUM and PNs, while the 
simulations between VUM and LNs will be added when use learning rule 2.[1] 
2.4.6 The process of simulation 
At the beginning, the synapses are weak and their value is under the threshold of the neurons. 
A particular compartment in each glomerulus is the input of VUM in this glomerulus, 
consequently, the change of synaptic occurs during learning results from the activity rates in 
each glomerulus.[1] 
2.4.6.1 The McCulloch-Pitts Model of Neuron 
The McCulloch-Pitts neuron model is introduced by Warren McCulloch and Walter Pitts in 
1943. The model adopts some features of real neurons, the inputs of which have either of two 
activities: excitatory to make the output fire and inhibitory not fire. The general equation is as 
below[44]: 
                          
1
( )
N
i i
i
y f I W
?
? ?                     
Ii (i=1,…,N) is the input and y is binary output, Wi(i=1,…,N) is weight value in the range of 
either (0,1) or (-1,1). The function is a linear step function, when the sum of IiWi above the 
 
 
threshold, the output y keeps the constant value 1. The function is described below: 
 
  y 
  
 1 
 
 
 
                            0 T ∑ 
                      Figure 2.15 non-linear threshold function 
 
The neuron model can be described as below network: 
 
 
 I1 W1 
  W2     ∑ output 
 I2 
                            
 WN 
 IN 
Figure 2.16: the McCulloch-Pitts Model adopted from [44] 
 
The function below describes the activity of neurons[1]: 
0
( ) [ ( )]
glom
i
i
o t F v t
?
? ?
                       
 
The output O(t) is the instantaneous firing frequency and only has two values, 1 stands for a 
spike occurs at time t and 0 stands for not . 
 
F is a non-linear threshold function, F(Xi(t)=1) means that the state Xj(t) of neuron j at time t 
is 1 is given by the function of the neuron membrane potential Vj(t) at time t, the lower 
threshold A decides the quantity of spontaneous activity, while the upper one B determines the 
value of the membrane potential that the maximal spiking frequency is reached: 
 
                P(X(t)=1) 
 
 1 
 
 
                  
 
 A             B V(t) 
                Figure 2.17: the firing frequency of VUM adopted from [1] 
The membrane potential V(t) in each glomerulus satisfies the next formula[1]: 
∑ F 
 
 
             ( ) ( ) ( )
iv P N P N
i i i
t
d
v t w O t S t
d
? ? ? ?         
?  is the membrane time constant of VUM, PNiw is the connection strength between 
PNs and VUM is glomerulus I, PNio (t) is the output of PNs and S(t) is the sucrose input. 
What is more, the sucrose-induced VUM activity synaptic changes can also occur between 
VUM and LN[1]: 
                  ( 1) * ( ( ) * ( ) )j i j i j i j iw t w v o t o t? ? ?           
The changes of synaptic strength are computed between pre and postsynaptic neural activity. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
3 Project Design 
3.1 Input and Output 
Odor stimuli which afferent the continuous value to reception cell is regarded as project 
input. This is simulated in Gaussian distribution form. Each RC(reception Cell) of 15 
has the maximal sensitivity to one kind of odor, and the rapidly decreasing values are 
received by the neighbors, for instance, if the No.8 RC has the most intensive response 
to one kind of odorant, the Gaussian distribution (?=0.5) for 15 RC is shown as below: 
 
 
                    Figure 3.1: odor processing 
The horizontal number stands for the RC, and the corresponding value received by RC 
is shown on the left.  
 
The output of project is the activity of 15 projection neurons and the VUMmx which is 
an integrated interneuron. The time interval between twice stimulation is 10ms, which 
is identical to the time delay. 
 
 
 
 
 
 
 
 
 
 
 
 
 
3.2 module design 
The general flow chart is shown as Figure 3.2. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
                       Figure 3.2: the model system 
3.2.1 Gaussian Module 
The Gaussian distribution formula is as below: 
f(x)=
1
 2π?2
e
?
(x??)2
2?2  
Because each kind of RC receives different continuous values if stimulated by 
Gaussian 
 module 
   Local 
interneuron 
Quasi-linear 
   functions 
Reception 
   Cell 
  Lateral 
 inhibition 
Projection 
  neuron 
 Associative 
  Learning 
VUM 
output 
 
 
different odorant, the mean of Gaussian function is taken between 1 and 15. ? is 
regarded as the open parameter and the value is adjusted from 0 to 1. 
 
3.2.2 The quasi-linear function 
                     P 
 
 1 
 
 
                  
 
 A    0        B V(t) 
                 Figure 3.3: non-linear threshold function 
The vertical value stands for the firing probability, the horizontal value is the 
membrane potential.  
 
In the program, the values of A and B are entitled below: 
   
         RC       LN       PN 
   A         -0.1       -0.2       -0.05 
   B         1.0       0.5       0.1 
                        Table 3.1: threshold values 
3.2.3 Reception Cell 
There are 15 RC arranged in a ring, each of them receives the continuous value from 
odor stimulation. When the accumulation reaches on or over the minimal threshold of 
the quasi-linear function, the activated signal will be probably produced and passed to 
LN(local interneuron). The greater the membrane potential is, the more probability for 
RC to make the firing signals. When the membrane potential reaches the maximal 
threshold, the values stored in the RC will be cleared and the membrane potential will 
be reset. 
 
For the single odorant from binary mixtures has different stimulation to different RC, 
so the relative distance between the two RCs who have most sensitivity to two 
odorants respectively may have the important effect on the cognitive behaviors. So 
the distance is considered as an essential overlapping parameter. If A stands for the 
RC having maximal sensitivity to one odor from binary mixture and B stands for 
another one, the distance is set as below: 
 
 
 
The cells between A and B 0 1 2 3 4 5 6 7 
The distance in overlap 1.0 0.875 0.75 0.625 0.5 0.375 0.25 0.125 
                    Table 3.2: the overlapping degree 
   
3.2.4 Local Interneuron  
There are 15 kinds of LN and each receive signals from RC, at the same time, they 
receive the inhibit signals produced 10ms ago from the neighboring LNs in the form 
of negative figures and the membrane potential from the VUM neuron. The sum 
potential will be computed in local interneuron and decided whether firing or not by 
quasi-linear function. Every local neuron can input their activated signal to 
neighboring 3 LNs on each side. The algorithm is as below: 
ij(t)=W1*Rj(t)+W2*Ii(t-d)+Wvum*V(t) 
where W1 is the connection strength between RC and LN, W2 is the connection 
strength between LN and neighbors and Wvum is the modifiable connection strength of 
the VUM branch. d is 10ms.   
3.2.5 Projection Neuron    
Projection neuron receives the inhibition signal from the local interneuron and fires 
when the membrane potential reaches the corresponding threshold. The formula is 
shown below: 
                              X=W*I(t-d) 
Where X is the membrane potential in PN, W is the connection strength between LN 
and PN. 
PN also outputs the signal to the VUM branch which connects with it. It will be 
introduced later. 
3.2.6 Lateral inhibition 
Lateral inhibition has already been found in animals’ olfactory bulbs. It is 
demonstrated by Galizia and Menzel that not only the direct neighbor can impose the 
inhibition, but also some indirect ones can produce this activity. The reasons are that 
the antennal lobe is like a ring, surrounded by all glomeruli. LN’s neurites travel more 
likely to the central neuropil instead of the neighbors[why honey bee]. Secondly, Not 
all of glomeruli with quite similar response features are direct neighbours[29]. Here, 
one LN can impose 3 neighbors on the each side, both directly and indirectly. 
However, the connect strengths are different according to the distance. For the direct 
neighbor, the connect strength is -0.2, and -0.1 for the indirect ones. 
 
 
3.2.7 The relationship of RC, LN and PN 
 
    odor stimuli                  odor stimuli     odor stimuli 
 
                                      
 RC  
 signal               signal                 no signal 
  
inhibit       inhibit   
  LN 
 inhibit no inhibit     inhibit no inhibit 
 
  PN 
 
                 
        0            1           0            1 
            Figure 3.4 : the relationship between RC, LN and PN 
 
It needs to know that the output of PN is uncertain. The diagram above just shows the 
maximal probable output of PN. 
3.2.8 Associative Learning 
Associative learning is used both in LN and PN modules during the training time. 
Synapse VUM is utilized to output the signals which is controlled by a non-linear 
function with the input of the total membrane potential. At this time, if PN or LN in 
this glomeruli also spikes, the feedback will strengthen the synaptic weight between 
VUM and the PN or LN. The diagram below describes this kind of activity. 
 
 
 
   
   
          
  
 
 
 
              Figure 3.5: Hebbian Learning in associative learning 
 
From the chart, it is clear that if the input and output are both firing sequentially, the 
connection weight between them is increased, or it is unchanged. The formula is 
demonstrated: 
 
         Wij(t+1)= 
Wij t + rij        if   Oi t = 1 and Oj t = 1    
Wij t            othewise                                
    
Where rij  is the learning rate and the value is 0.5, Oi t  is the output of PN or LN 
and Oj t  is the output of VUM. 
There are two kinds of learning methods that are applied in the program. One is that 
only the weight between PN and VUM is modifiable. In the other one, not only the 
weight between PN and VUM, but also the weight between LN and VUM is involved. 
3.2.9 VUM output 
First, the membrane potential in each glomeruli is computed first, the value is 
changed according to the time. The algorithm during training time is described below: 
Vi(t)=Wi
PN Oi t + S t ??
dv
dt
  
Where W is the modifiable strength between PN and VUM, Oi t  is the output of PN 
at time t, S(t) is the external input and the value is 0.5. ? is the time constant. 
Then at the time t, the output of VUM is computed in next formula: 
 
 
                          O(t)=f( Vi(t
14
0 )) 
3.3 GUI Design 
 
Figure 3.6: program GUI 
 
On the upper-left corner is the general model architecture proposed by Linsgter and 
Smith. Some function buttons will be explained below: 
 and  are different learning rules that different synapses are 
submitted to Hebbian Learning. 
 performs the function of pure odor stimulation. The LN and PN output will 
be displayed in the middle part of the GUI. 
 performs the function of binary odor mixture stimulation.  
 adds the function of associative learning. The output will be 
 
 
displayed on the bottom two lines. For example: 
 
 
                       Figure 3.7: the output sample 
It shows the response of VUM neuron. Arrows stand for stimulus onset and offset. 
The horizontal axis represents the time. The time interval is 10 ms. The stimulation of 
pure odorant O1, O2 and mixtures O1+O2 lasts for 500 ms. The stimulation of 
S(sucrose) lasts for 250 ms.  
 
The first line shows during a control simulation, O1 is paired with sucrose, and then 
during the test stage, the response to the components of O2, O1 and the mixtures 
respectively. 
 
The second line shows during the training time, the mixtures are paired with sucrose 
from 250ms to 500ms, and next is the response to the components of O2, O1 and the 
mixtures respectively. 
 
The button “distance” adjusts the overlapping parameter, the diagram below shows 
the changeable values: 
 
 
Figure 3.8: the overlapping degree 
In the middle part, 15 blue lines corresponding to the output of 15 local interneurons 
during the 500ms training time. And 15 red lines displayed the outputs of the 
projection neurons. 
 
For each LN on the right side, there is a corresponding PN output on the left side. For 
instance, when adopting the LR1, the distance is 0.875, the responses of LNs and the 
corresponding PNs are shown below: 
 
 
 
Figure 3.9: the relationship between LNs and PNs 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
4 Experiments and Results 
4.1 LN, PN and lateral inhibition 
When O1 is involved in the training stage as the conditioned stimulus, the No.8 RC 
has the maximal sensitivity to the odorant, because of the Gaussian distribution with 
the No.8 RC is regarded as the distribution center, its neighbors have different 
sensitivity to it. The outputs of 15 LNs within 500ms are displayed below: 
 
 
Figure 4.1 LN output sample 
 
It is known that three local interneurons have continuous strong firing rates 
throughout the whole process. For the neurons on two sides whose responses are not 
so strong, they are affected by their neighbors’ inhibit signals.  
 
For the corresponding projection neurons, the outputs are displayed in Figure 4.2. 
For the two projection neurons in the glomeruli in where the local interneurons are 
circled by red lines, they have more firing frequencies. This is because that the LNs 
inhibited by the neighbors do not impose the inhibition on the connected PNs. By 
comparison, the No.8 projection neuron is completely inhibited. 
 
When these projection neurons are associated with VUM, the synaptic changes will 
be always added on the weights involved in the circled PNs.  
 
 
 
             Figure 4.2: PN output sample 
When it comes to the binary mixture stimulation, the process is a little more complex. 
When the overlapping parameter is 0.125, the output of PNs is shown in Figure: 
 
Figure 4.3 PN output sample 
For the distance of two reception cells which are most sensitive to two odorants 
respectively is very far, there is seldom interruption for the single LN’s odor 
processing. 
 
However, for the overlapping parameter is 0.375, some LNs are disturbed by the 
neighbors, and the output computed by program is as below: 
 
 
 
 
Figure 4.4: PN output sample 
It can be seen that some local interneurons are disturbed by their neighbors, the output 
of these LNs is different from that stimulated by the pure odorant. The more firing 
rates are increased and shown in below PNs. 
 
 
Figure 4.5: LN output sample 
 
 
 
4.2 Learning 
The basic function of the model is that it can differentiate the odorants by a kind of 
learning ability.  
Figure presents that VUM doesn’t change its spiking frequency responding to O1, O2 
and the mixture without learning. 
 
 
Figure 4.6: the response of VUM without learning 
Ii is clear that the VUM neuron makes the similar response to O1, O2 and the mixture, 
it is difficult for VUM to apart one component from the other by the response no 
matter whether the pure odorant or the mixture is used in the training stage. 
However, when the learning is involved in the training phase, the change can be seen 
below: 
 
 
                 Figure 4.7: the response of VUM with learning 
When the sucrose is introduced 250ms after the start of odorant stimulation in the 
training stage, the VUM has intensive response to the conditioned stimulus. It is clear 
that when O1 is paired with sucrose, VUM increases the spiking frequency to O1 and 
the mixture(contains O1), but does not change the firing frequency to O2. When the 
mixture(O1 and O2) is adopted as the conditioned stimulus, the firing rates are 
increased in O1, O2 and the mixture. 
 
Learning leads to the change of certain connection weights associated with some PNs 
and LNs. However, it is uncertain about the initialized weight value and the relevant 
learning rate. In the experiment, the initialized value is set to 0.25 and the learning 
rate is set to 0.8.  
 
When adopting LR1 and pure odor stimulation, the connection weights of all 
glomeruli after learning are shown below: 
 
 
 
Figure 4.8: the change of synaptic weights 
When adopting LR2, the graph is described as: 
 
Figure 4.9: the change of synaptic weights 
 
The bar chart below shows the average response of VUM to O1, O2 without being 
paired with sucrose. 
 
 
 
          
Figure 4.10: the response of VUM without learning 
 
1 stands for the response of the VUM neuron to O1 in the test stage. And 2 presents 
the response to O2. It shows the similar responses to components in the binary 
mixture. 
Then after the training with sucrose, the data of response of VUM is recorded as 
below: 
 
 
       Figure 4.11: the response of VUM with learning 
 
It is clear that the average response (0.36) to O1 after learning with O1 is much higher 
than that to O2 (0.14). And the response to O1 (0.25) after VUM was trained with the 
mixture is similar with that to O2 (0.23). 
 
 
4.3 Generalization  
The basic method to analyze the generalization is to compute the activity of the VUM 
neuron. The response of VUM to the conditioned stimulus and unlearned stimulus are 
gained and computed. When the response to the unconditioned stimulus is above the 
threshold, the phenomenon of generalization is found.   
When adopting learning rule 1, the ratio of the response to unconditioned stimulus 
over the response to learned one is computed 5 times for each kind of the binary 
mixture and shown below: 
 
 
Figure 4.12: Generalization in LR1 
 
In the figure above, the horizontal axis presents the degree of overlap and the vertical 
axis stands for the ratio, which is computed by the firing numbers of VUM to the 
unconditioned odor divided by the numbers to the learned one.  
 
Generalization occurs when the ratio is above 0. When the overlapping degree is 0.5, 
the model has strong generalization, this happens just when the stimulation by 
unlearned odor to the glomeruli are outside the radius of conditioned odorant 
stimulation. The described figure is shown: 
 
 
 
 
 
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
0 0.2 0.4 0.6 0.8 1
 
 
                   O2 
                   
 O1 
 
 
 
                               0.5 
 
 
 
 
  
 
Figure 4.13 : the overlapping 
By contrast, the weak generalization occurs for other circumstances. As normal, the 
strong generalization should occur when the degree of overlap is above 0.5, however, 
the lateral inhibition impose this type of signals to the neighbors which suppresses the 
strong generalization and make it weak or distinguish. But in general, the ratio is 
bigger with the increase of the degree of overlap (except 0.5). 
When it comes to LR2, the data is recorded below: 
 
 
Figure 4.14: Generalization in LR2 
Different from LR1, when the overlapping degree is above 0.5, the results are higher 
than previous ones. It seems that the effect of lateral inhibition is not as strong as LR2. 
LR1 only trains the connection weights involved in the activity of PNs which are 
sensitive to the conditioned odorant, however, certain connection weights are also 
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
0 0.2 0.4 0.6 0.8 1
 
 
trained in LR2 where some relevant PNs are associated with the unlearned odorant. 
So the lateral inhibition fails to completely restrict these PNs activity.  
 
This is different with the model of Linster et al[1]. In their model, when adopting LR2, 
the similar pattern is found compared with LR2. 
 
In their data graph[1] below, Generalization is always weak except when the 
overlapping degree is 0.5. When the degree is 0.125, 0.25, 0.625 or 0.75, 
generalization is restricted within 0.1 or so, and less than 0.4 for generalization when 
the degree is 0.375 or 0.875. However, compared with their data, generalization is 
stronger when the degree is 0.625 or 0.75, which is around 0.3~0.6, and this 
difference is caused by the training of the connection weights involved in PNs which 
have been analyzed before. 
   
 
 
Figure 4.15: Linster et al’s data distribution adopted from [1] 
4.4 Overshadowing 
In this part of experiment, the phenomenon of overshadowing is identified. It happens 
when the response of VUM to an odor A in the testing stage after that odorant A 
training is stronger than the response to A after the mixture (including A) training. 
When using LR1, the overlapping degree is set to 0.75, the responses of VUM after 
pure odorant training and after the mixture training are shown separately: 
 
 
 
 
Figure 4.16: the VUM output sample 
In testing stage, each stimuli lasts for 500ms. The firing times during 500ms for pure 
odorant training are 13. By contrast, the spiking times for mixture training are 6. This 
is identified biological cognitive behavior. 
Next, each combination is tested and the data is recorded and displayed below: 
 
 
Figure 4.17: Overshadowing in LR1 
 
The horizontal axis stands for the overlapping degree, the vertical axis represents the 
ratio for the firing times of response to mixture divided by those to pure odorant.  
 
For each combination of the mixture, the ratio is computed 5 times. The 
overshadowing occurs when the value is below 1. It is known that for each 
combination, overshadowing occurs to different extent.  
 
In general, overshadowing becomes stronger with the increase of the overlapping 
degree. When the two components are far away from each other, for example 0.125, 
the weak phenomenon is found and the ratio is around 0.9. The similar phenomenon is 
also found when the degree is within 0.25~0.5. Then, strong overshadowing begins 
from 0.625. Except one sample in 0.75 has no overshadowing, it lies in all other 
samples within 0.625~0.875. The strongest overshadowing is found in 0.875 and the 
value is around 0.4.  
 
Because the overlapping degree decides the extent of the interaction among the LNs, 
 
 
the large degree demonstrates the strong interaction among the LNs. This kind of 
interaction lies in LNs activity is regarded as lateral inhibition. Because the range of 
lateral inhibition is within 0.625~0.875, when the degree is out of the lateral inhibition 
region, overshadowing is weakened sharply.  
 
LR2 is also applied and the data is recorded below, the sample distribution is similar 
like LR1 but a little different. 
 
 
                     Figure 4.18: Overshadowing in LR2 
 
Just like LR1, the data of LR2 presents the similar trend. However, the strongest 
overshadowing occurs when the overlapping degree is 0.625 instead of 0.875. And 
when the degree is over 0.5, some samples still fails to produce overshadowing.  
 
When the lateral inhibition is imposed, the ratio is ranged from around 0.6 to around 
0.9. It is generally bigger than values when using LR1. It is possible that the effect of 
lateral inhibition is weakened by some LNs’ strong activity, which is caused by some 
connection weights associated with learning of unconditioned odorant. 
  
Compared with Linster et al’s overshadowing experiment, it is similar that the 
overshadowing occurs clearly when the degree is bigger than 0.5. 
 
However, their data shows that when the degree is below 0.5 (including 0.5), 
overshadowing seldom happens and the ratios are all near 1.0, which means the 
response to the very odorant after pure training is almost equal to that after mixture 
training. In my experiment, the range of the ratio for the degree within 0.125~0.5 is 
larger, which is caused by the different time constant and variance of Gaussians. Their 
experiment data graph is shown below[1]: 
 
 
 
 
 
Figure 4.19: Linster et al’s data distribution adopted from [1] 
4.5 time constant  
According to section 2.5, the integrate-and-fire model is expressed below: 
?
dVm (t)
dt
+Vm(t)=RmIin(t)=e(t) 
Where ? is the membrane time constant, it is open parameter and part of research in 
the experiment.  
In reception cell, the Gaussian distribution is applied and the membrane potential is 
fluctuated in line with N(0, ?). 
V(t)=e(t)+N(0, ?) 
If e(t)<0, then set e(t)=0. 
And the variance of membrane potential V
’
(t) is expressed below: 
V
’
(t)= 
1
 2π?2
exp?(?
t2
2?2
) 
Then the total potential is like this 
V(t)=e(t)+ 
1
 2π?2
exp?(?
t2
2?2
) 
The graph below compares the variance of membrane potential with the different time 
constant. 
 
 
 
 
 
 
 
 
 
 
 
                                   ?=0.5ms 
 
 
 
 
                                      ?=1ms 
 
                                                         ?=10ms 
 
  
Figure 4.20: time constant with Gaussian distribution 
 
It is interesting to invest the relationship between time constant and the lateral 
inhibition. Because the lateral inhibition imposes great effect on a series of cognitive 
behaviors, the research on time constant and the lateral inhibition could disclose some 
connections between cognitive behaviors and time constant. 
 
In the experiment, the time constant value is set to 0.5ms, 1ms, 10ms respectively. 
The outputs of 15 LNs are different. When ?=0.5ms, adopting LR1, the response after 
pure odorant stimulation during 500ms epoch is like below: 
 
 
Figure 4.21: the output of LNs when ?=0.5ms 
 
 
 
Compared with Figure, when the time constant is set to 1ms, the neighbor neurons 
sensitive to the trained odorant will increase their firing rates while the central neuron 
of odor focus decrease the spiking frequency. The relevant graph is shown below: 
 
Figure 4.22: the output of LNs when ?=1ms 
When it comes to 10ms, it is clear that every PN has the similar firing times during 
the beginning half time, however, after the break of straight spiking, it is relative late 
for the neurons on the sides to recover firing from the short break comparing with the 
central neurons.  
 
Figure 4.23: the output of LNs when ?=10ms 
Next, the study about the relationship among generalization, overlapping degree and 
 
 
time constant when adopting LR1 is done and the recorded data is on the graph. 
 
 
Figure 4.24: time constant, overlapping and generalization 
 
From the diagram, 0.125-0.875 is the overlapping degree of the binary components. 
The vertical axis stands for the ratio R1/R2, where R1 represents the response to the 
conditioned odor and R2 is the response to the unlearned odorant. For each 
circumstance, five values are computed and the average value is taken. 
 
It can be seen that in general, generalization is always high when the time constant is 
10ms, and there is little relationship between the degree and the ratio. The ratio of 
around 0.9 explains that VUM could weakly differentiate the conditioned odor from 
the unconditioned one.  
 
The similar trends lie in 0.5ms and 1ms. Data is in the range of 0-0.2 except the cases 
with the degree 0.5. Generalization is a little higher for 0.5ms than that for 1ms. For 
the overlapping degree which is 0.5, the sample for 1ms is near to 0.7 and almost 0.2 
higher than that for 0.5ms. 
 
In the experiment, it is clear that the small time constant contributes to low 
generalization, the VUM neuron could make more precise judge upon the binary 
components. And with the increase of time constant, this function is becoming weaker 
and weaker.  
 
Consequently, there must be a critical point for time constant that the variance of 
generalization is in relationship with the overlapping degree within this point. When 
time constant is larger than this critical point, the lateral inhibition also imposes the 
effect on neurons relevant to unconditioned odor. It means time constant is in line 
with the effect of the lateral inhibition.  
However, it has not been found out yet that what this critical point is, so it is a 
 
 
question left for the future work to look for this critical point.  
4.6 Summary 
In this chapter, several experiments are introduced and the results of data are analyzed. 
These experiments are divided into implement part and research part. 
 
In implement part, generalization and overshadowing phenomenon are introduced and 
the relationship between phenomenon and the lateral inhibition is identified. The 
relevant diagrams are analyzed and compared with previous results. Although the 
similar data distribution and trend are verified, there are some small differences in the 
range of data. The differences come from two reasons. One is that the values of open 
parameters such as the synaptic weight, time constant are not fixed and they are 
adjusted according to the structure of the experimental model. Another is that 
adopting the Gaussian white noise increases some uncertainty. 
 
In research part, one of the open parameter time constant is researched. From the 
experiment, the effect of time constant on one of cognitive behaviors generalization is 
disclosed, the high time constant contributes to the strong response to the untrained 
odorant. And a critical point is supposed that when time constant is over the point, the 
lateral inhibition will influent the whole system so that there is seldom relationship 
between the overlapping degree and the generalization ratio. However, how to 
identify the critical point is a problem and will be further researched in the future.  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
5 Future Work 
5.1 Improvement of Odor Processing 
In the model, the odorant is simulated by the Gaussian distribution, and the spiking 
probability is line with the uniform random. This is simple and easy to process the 
binary mixture but does not meet the objective laws. It is more reliable and reasonable 
to adopt the Christiane and Thomas’ method, their algorithm to measure a reception 
cell firing or not is as below[45]: 
P(xi(t)=1)= 
1
?i 2π
exp?(?
(t?nT )2
2?i
2 )
N
n=1  
The probability of neuron I at time t spikes is expressed as Gaussian function. Where 
?i  measures the distance from neuron i to the central neuron of the odor focus, the 
expression is shown below[45]: 
              ?i = ?max + exp ?
d i
2
5.0
 (?0 ? ?max ) 
Where ?0 is the neuron just at the odorant focus.  
In the future work, the algorithm will be applied in the model and the performance 
will be compared with the initial one. 
5.2 Open Parameter 
It is still uncertain how to decide signal transmission delay and time interval. For 
convenience, signal transmission delay is identical to time interval in my program 
which is 10ms. In this way, it is easy to operate the delay data with the change of time. 
In the future, both factors will be adjusted to adapt to the model. 
 
Time constant, another open parameter, is researched in the experiment. However, the 
critical point has not been decided yet. The research on the critical point helps finding 
the influent scope of lateral inhibition. 
5.3 Classification Method 
In this essay, some cognitive behaviors are identified. The VUM differentiating the 
learned odorant from the unconditioned one which is similar to classical conditioning 
is simulated in program. However, this kind of classification is based on the training 
of one particular odorant.  
In the future work, the classification based on the built model with no training will be 
researched. 
In the whole model, the output of projection neuron is paramount to the AL layer, so 
 
 
the research on the PN spiking is meaningful. 
The classification method is based on R.Huerta’s idea, which is divided into two steps: 
the first is the nonlinear transformation from the antennal lobe(AL) to the mushroom 
body(MB), and the second is the classification in the MB. 
In the beginning, the spatiotemporal output of 15 PNs will be recorded, take 2 of 15 
PNs as examples[46]: 
 
           Figure 5.1: the state vector x
i
  
The nonlinear transformation is as below[46]: 
Yj= 
1,        if        cji xi ? ?KC ≥ 0
NAL
i=1
0,          otherwise                           
  
where xi is the state vector mentioned in Figure, NAL is the number of PNs, ?KC  is 
the firing threshold and c is the connectivity matrix. The output yj is the vector in MB. 
In this step, y
i
=[y1,y2,…,yAL] for the corresponding x
i
 is computed. The number of 
neurons decides the dimensional space. Take 2 neurons as an example, the positions 
of y
i
 in a two dimensional space are displayed like this[46]: 
 
Figure 5.2: nonlinear transformation from AL to MB 
 
Then the linear classification in the MB is continued[46]: 
                 zi= 
1,       if     Wij yj ? ?LB ≥ 0
NKC
j=1
0,                     otherwise              
  
where yj is the state vector in Figure, Wij is the connectivity matrix and ?LB  is the 
threshold in the MB. After the hebbian learning in adjusting the Wij, the output of Zi is 
the result of classification. During this process, Wi=[Wi1,Wi2,…,Wij] is computed and 
plays as a hyperplane in the space. The figures which are above this hyperplane are 
claasified from ones under the plane. 
 
 
 
The diagram shows how this hyperplane divides the data in a two-dimensional 
space[46]: 
 
 
      Figure 5.3: linear classification in MB 
 
In this way, the odorants are discriminated in the mixture. In future work, it is 
interesting to implement this process utilizing the built model. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
6 Conclusion 
This essay has introduced a re-implement honey bee olfactory model and done some 
research based on this model. 
 
In chapter 2, the relevant background knowledge is introduced. First, honey bee 
olfactory system and some cognitive behavior triggered by this system are described. 
Then, the academic nouns such as generalization, overshadowing and the relevant 
mechanism involved in the experiment are presented. Next, the model and some 
classic algorithms associated are shown.  
 
Chapter 3 mainly describes how the model is constructed and designed. Because the 
paper which the model is on the basis of did not describe the model clearly and has 
some ambiguous places, it is a challenging task to design the model in every detail 
and set many open parameters. The program’s GUI is shown that is an essential part 
to analyze the output data.  
 
In next chapter, a serious of experiments had been done and the results are analyzed. 
In the beginning, the connections among RC, LN and PN are identified. After that, the 
experiments are made around the effect of the lateral inhibition, a paramount 
phenomenon occurs in activity of LNs. The cognitive behaviors generalization and 
overshadowing emerged in the experiments and several data diagrams were made to 
analyze the relationship between behaviors and the lateral inhibition. Compared with 
previous paper’s data pictures, the similar data trend and distribution are found 
although the range of taken value is a little different.  
 
By the experiments, the lateral inhibition produced in the binary mixture stimulation 
when the overlapping degree is 0.5 contributes the high generalization which is 
clearly different from the other circumstances. And the overshadowing apparently 
occurs when the overlapping degree is above 0.5, which connects tightly with the 
lateral inhibition. For the research part, the time constant is further studied to disclose 
the effect of it to the olfactory system. In the experiment, it is found that within an 
uncertain critical point, the increase of time constant leads to the stronger 
generalization. Therefore, time constant must strengthen the activity of lateral 
inhibition. When the time constant is bigger than the critical point, the generalization 
is always high for each overlapping style.  
 
Chapter 5 is the work left for the future. In this chapter, how to decide the value of 
several open parameters and evaluate the influences is a tough work. For the odorant 
processing, an advanced algorithm is introduced and the implement of this algorithm 
will be done and therefore the performance can be compared with the present model. 
Finally, the relevant classification method is introduced and this interests me mostly. 
Nonlinear transformation from the AL to the MB aims to distribute the data in 15 
 
 
dimensional space. By the hebbian learning, the hyperplane is decided wich divides 
the space into two parts. The data above the plane is separated from others. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
7. References 
1  Linster, C and Smith, B.H..(1997). A computational model of the response of honey bee 
antennal lobe circuitry to odor mixtures: overshadowing, blocking and unblocking can arise 
from lateral inhibition. Behavioural Brain Research 87,1-14. 
2  Drwin, C.(1871). The descent of Man, and Selection in Relation to Sex(London: John Murray). 
3  Chittka, L and Niven, J.(2009). Are Bigger Brains Better? Current Biology 19, 995-1008. 
4  Menzel, R., and Giurfa, M. (2001). Cognitive architecture of a mini-brain: the 
honeybee. Trends Cogn. Sci. 5, 62–71. 
5  Goldenberg, E., Garcowski, J., and Beer, R.D., (2004). May we have your attention: Analysis of 
a selective attention task. In From Animals to Animats 8: Proceedings of the Eighth 
International Conference on the Simulation of Adaptive Behavior, S. Schaal, A. Ijspeert, A. 
Billard, S. Vijayakumar, J. Hallam and J.-A. Meyer, eds. (MIT Press), pp. 49–56. 
6  M.Izhikevich, E.(2007). Dynamical systems in neuroscience: the geometry of excitability and 
bursting. Cambridge: The MIT Press. 
7  Cleland, T. A. and Linster, C.(2005). Computation in the Olfactory System, Chem.Senses 30: 
801-813. 
8  http://nelson.beckman.illinois.edu/courses/neuroethol/models/bee_labor/ bee_labor.html 
9  Flanagan D & Mercer AR (1989) An atlas and 3-D reconstruction of the antennal lobes in the 
worker honey bee, Apis mellifera L. (Hymenoptera: Apidae). International Journal of  Insect 
Morphology and Embryology 18: 145-159. 
10  Huerta R, Nowotny T, Garcia-Sanchez M, Abarbanel HDI, Rabinovich MI (2004) Learning 
classification in the olfactory system of insects. Neural Comput 16:1601–1640. 
11  Gao, Q., Yuan, B., & Chess, A. (2000). Convergent projections of Drosophila olfactory 
neurons to specific glomeruli in the antennal lobe. Nat. Neurosci., 3(8), 780–785. 
12  Rodrigues,V. (1988). Spatial coding of olfactory information in the antennal lobe 
of Drosophila melanogaster. Brain Res., 453, 299–307. 
13  Fonta, C., Sun, X. Masson, C.. (1993). Morphology and spatial distribution of bee antennal 
lobe interneurons responsive to odours, Chemical Senses, 18 ,101–119. 
14  Sun, X., Fonta, C. and Masson, C.. (1993). Odour quality processing by bee antennal lobe 
neurons, Chemical Senses 18 ,355–377. 
15  Hammer, M. (1993) Nature 366, 59–63. 
16  Rescoria, R.A. A. Rev. Neurosci. 11, 329-352(1988). 
17  Rescoria, R.A. & Wagner, A.R. in Classical conditioning two: Current Research and 
Theory ,64-99 
18  Wagner, A.R. in Information Processing in Animals: Memory Mechanisms, 5-47. 
19  Hawkins, R.D. & Kandel, E.R. Psychol. Rev, 91, 375-391(1984). 
20  Hammer, M.(1993). An identified neuron mediates the unconditioned stimulus in associative 
olfactory learning in honeybees. Nature, 366(4). 
21  Frisch, K. von.(1967). The Biology of the Honey Bee. Harvard Univ. Press, Boston. 566pp. 
22  Dionne, V. E., and A. E. Dubin. 1994. Transduction diversity in olfaction.J. Exp. Biol. 
194: 1-21. 
23  Smith, B.H.(1996). The Role of Attention in Learning About Odorants. Biol. Bull. 191:76-83. 
 
 
24  Smith, B. H., and R. Menzel.(1989). An analysis of variability in the feeding motor program of 
the honey bee: the role of learning in releasing a modal action pattern. Ethology 82: 68-81. 
25  Pearce, J. M.(1994). Similarity and discrimination: a selective review and a connectionist 
model. Psychol.Rev.101:587-607. 
26  Bitterman, M. E., R. Menzel, A. Fietz, and S. Schafer.(1983). Classical conditioning of 
proboscis extension in honeybees, Apis mellifera. J.Comp.Psvchol.97: 107-119. 
27  Pelz, C, Gerber, B and Menzel, R. (1997) Odorant intensity as a determinant for olfactory 
conditioning in honeybees: roles in discrimination, overshadowing and memory 
consolidation, The Journal of Experimental Biology 200, 837-847. 
28  Smith B.H. and Cobey, S. (1994). The olfactory memory of honey bee, Apis mellifera. II. 
Blocking between odorants in binary mixtures, J. Exp. Biol., 195,91–108. 
29  Sahley, C., J. W. Rudy, and A. Gelperin. 1981. An analysis of associative learning in a 
terrestrial mollusc. I. Higher-order conditioning, blocking and a transient 
US-pre-exposureeffect. I.Comp. Physiol. 144: 1-8. 
30  Smith, B. H., and Cobey,S. 1994. The olfactory memory of honey bee, Apis mellifera: II. 
Blocking betweenodorants in binary mixtures.J.Exp.Biol.195:91-108. 
31 Gerber, B. and Ullrich, J. (1999). No evidence for olfactory blocking in honeybee classical 
conditioning. J. Exp. Biol. 202:1839 -1854. 
32 Hosler, J. and Smith, B. (2000). Blocking and the detection of odor components in blends. J. 
Exp. Biol. 203:2797 -2806. 
33 Gascuel, J. and Masson, C. (1991). Quantitative electron microscopic study of the antennal 
lobe in the honey bee, Tissue Cell, 23, 341–355. 
34 Sun, X., Fonta, C. and Masson, C.(1993). Odour quality processing by bee antennal lobe 
neurons, Chemical Senses 18 ,355–377. 
35 Fonta, C., Sun, X. Masson, C. (1993). Morphology and spatial distribution of bee antennal 
lobe interneurons responsive to odours, Chemical Senses, 18, 101–119. 
36 Hagan, M. T., Demuth, H. B., Beale, M.. Neural Network Design. Page 13-2. 
37 Classical conditioning. http://en.wikipedia.org/wiki/Classical_conditioning. 
38 Hebbian theory. http://en.wikipedia.org/wiki/Hebbian_theory. 
39  Samuelides, M., Thorpe, S. &Veneau, E.(1997). Implementing hebbian learning in a 
rank-based neural network. Computer Science, 1327: 145-150. 
40  Thorpe, S.J., Fize, D & Marlot, C.(1996). Speed of processing in the human visual system. 
Nature (381): 520-522. 
41  Abbott, L.F. (1999). "Lapique's introduction of the integrate-and-fire model neuron (1907)". 
Brain Research Bulletin 50 (5/6): 303-304. 
42  Koch, Christof; Idan Segev (1998). Methods in Neuronal Modeling (2 ed.). Cambridge, MA: 
Massachusetts Institute of Technology. ISBN 0-262-11231-0. 
43 Hammer, M. and Menzel, R.. (1995). Learning and memory in the honey bee, J. Neurosci., 9 , 
3154–3162. 
44 The McCulloch-Pitts Model of Neuron. 
http://www.ece.utep.edu/research/webfuzzy/docs/kk-thesis/kk-thesis-html/node12.html. 
45  Linster, C. and Cleland, T.A..(2001). How Spike Synchronization Among Olfactory Neurons  
an Contribute to Sensory Discrimination. Journal of Computational Neuroscience, 10: 
187-193. 
 
 
46  Huerta R, Nowotny T, Garcia-Sanchez M, Abarbanel HDI, Rabinovich MI (2004) Learning 
classification in the olfactory system of insects. Neural Comput 16:1601–1640. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 

 
 
ABSTRACT 
The Micro-architectures of modern processors have become sophisticated and complex due 
to the advancement in VLSI technology. Modern computer architectures rely extensively on 
advanced branch prediction schemes to keep their ever lengthening pipelines filled with 
instructions. These mechanisms are so crucial to performance that hardware vendors publish 
very little about how they actually work, instead keeping the details as "secret sauce". The 
thesis consists of a set of micro benchmarks to automatically determine the underlying branch 
prediction architecture of Intel Nehalem and ARM processors. 
A number of micro benchmarks have been developed and tested to reveal the organisation 
details of Branch Target Buffer Predictors and the Loop Predictors. The thesis targets 
ARM11 processors and Intel core i3 and core i5 processors. The branch misprediction results 
are collected for every micro benchmark designed and the analysis was performed to reveal 
the structure of the branch predictor.  
An automated analyzer is developed to automatically analyse the results and reveal the 
branch prediction architecture without involving any manual analysis of the results. This 
helps greatly in designing compilers that are aware of their underlying architecture which can 
significantly enhance the performance of the application.  
Based on the results of the developed micro benchmarks, the primary contributions of the 
experiments carried on the Nehalem architecture are: 
? Provision to discover the organisation of underlying Branch Target Buffer predictor. 
? Revealed the structure of the Loop Prediction Unit implemented. 
? Developed an automated analyser that took the results obtained from the micro 
benchmarks developed, and generated the structure of the branch predictor. 
   
 
 
 
 
 
 
 
i 
  
 
                         ACKNOWLEDGEMENTS 
I would like to express my love and gratitude to my beloved family, for their understanding, 
support and endless love throughout the duration of my studies, especially my mother Shobha 
S Mukartihal, my father Shivaputra D Mukartihal and my brother Santosh. 
The work carried out would not have been possible without the guidance and assistance of a 
number of people who certainly deserve special mention. 
I would like to express my gratitude to my supervisor, Mr Simon McIntosh-Smith for his 
motivation, encouragement, constant guidance and support throughout my work.  
My sincere thanks to Professor David May, whose valuable insights through the Advanced 
Computer Architecture course inspired me to choose a project on Branch Predictors.     
I would like to mention my special thanks to Mr David Power, Viglen Ltd, for providing 
access to their machines upon request from my supervisor. 
I would also like to thank, Mr Syed Rahman, IT Support Specialist, Zone E Team Support, 
for his support in setting up a core i5 system. 
I am heartily thankful to my friend Pallavi Anantharamu, for her constant support and 
motivation to perform better each time.      
 
 
 
 
 
 
 
 
 
 
ii 
  
 
Table of Contents 
ABSTRACT ........................................................................................................................................... I 
ACKNOWLEDGEMENTS ................................................................................................................ II 
LIST OF FIGURES............................................................................................................................ VI 
LIST OF TABLES........................................................................................................................... VIII 
CHAPTER 1. INTRODUCTION ....................................................................................... 1 
1.1 Aims and Objectives .....................................................................................................................1 
1.2 Outline ...........................................................................................................................................1 
1.3 Motivation .....................................................................................................................................2 
1.3.1 Architecture aware compilers ................................................................................................2 
1.3.2 Branch predictor design verification ......................................................................................2 
1.3.3 Bridge gap between Academia and Industry .........................................................................2 
CHAPTER 2. BACKGROUND RESEARCH ................................................................... 3 
2.1 Introduction ..................................................................................................................................3 
2.2 Branch Prediction .........................................................................................................................3 
2.3 Importance ....................................................................................................................................3 
2.3.1 Performance Impact ...............................................................................................................4 
2.4 Branch Prediction Techniques ....................................................................................................5 
2.4.1 Static Branch Prediction.........................................................................................................6 
2.4.2 Dynamic Branch Prediction ...................................................................................................6 
2.5 Previous Work ............................................................................................................................12 
CHAPTER 3. INDUSTRIAL BRANCH PREDICTORS ............................................... 14 
3.1 ARM PROCESSOR ...................................................................................................................14 
3.1.1 ARM 7 .................................................................................................................................14 
3.1.2 ARM 8 .................................................................................................................................14 
3.1.3 ARM 9 .................................................................................................................................14 
3.1.4 ARM 11 ...............................................................................................................................15 
3.2 Branch Prediction Techniques - Intel .......................................................................................16 
3.2.1 Branch Prediction in Intel Atom ..........................................................................................16 
3.2.2 Branch Prediction in Intel Nehalem Architecture ................................................................16 
 
iii 
  
 
 
CHAPTER 4. TOOLS AND ENVIRONMENT SETTINGS ......................................... 19 
4.1 Tools .............................................................................................................................................19 
4.1.1 ARM Workbench IDE v4.0 and RVDS ...............................................................................19 
4.1.2 Intel Vtune ...........................................................................................................................20 
4.2 Branch Prediction: Intel Nehalem Architecture ......................................................................23 
CHAPTER 5. BRANCH PREDICTION STRUCTURE OF ARM ............................... 25 
5.1 Introduction ................................................................................................................................25 
5.2 Algorithm flow developed ..........................................................................................................25 
5.3 Branch Organisation Tests ........................................................................................................27 
5.3.1 BTB capacity test .................................................................................................................27 
5.3.2 BTB indexing tests ...............................................................................................................29 
5.3.3 BTB tag bits test ...................................................................................................................30 
5.3.4 2-bit saturation counters implementation .............................................................................31 
5.4 Summary of BTB structure  ......................................................................................................34 
CHAPTER 6. BRANCH TARGET BUFFER PREDICTOR ANALYSIS AND 
RESULTS  ..................................................................................................................... 35 
6.1 Introduction ................................................................................................................................35 
6.2 Contributions ..............................................................................................................................36 
6.3 BTB Organisation tests ..............................................................................................................36 
6.3.1 BTB capacity test and results ...............................................................................................37 
6.3.2 BTB set associative analysis and results ..............................................................................42 
6.3.3 BTB indexing Analysis ........................................................................................................43 
6.3.4 BTB MSB tag bit analysis and results .................................................................................46 
CHAPTER 7. LOOP PREDICTOR STRUCTURE ANALYSIS AND RESULTS ..... 47 
7.1 Introduction ................................................................................................................................47 
7.1.1 Background ..........................................................................................................................47 
7.2 Contributions ..............................................................................................................................48 
7.3 Loop Predictor organisation analysis .......................................................................................49 
7.3.1 Maximum Counter Length analysis and results ...................................................................49 
7.3.2 Loop capacity analysis and results .......................................................................................50 
7.3.3 Loop MSB analysis and results ............................................................................................53 
7.3.4 Loop LSB analysis and results .............................................................................................54 
7.3.5 Loop set associativity analysis and results ...........................................................................55 
7.3.6 Loop Tag MSB bit analysis and results ...............................................................................56 
7.4 Relationship between Loop Predictor and BTB ......................................................................56 
iv 
  
 
7.5 Replacement policy .....................................................................................................................57 
 
CHAPTER 8. AUTOMATIC ANALYSER ..................................................................... 59 
8.1 Block Diagram ............................................................................................................................59 
8.2 Automatic Analyser – Branch target buffer .............................................................................60 
8.3 Automatic Analyser – Loop Predictor ......................................................................................60 
8.4 Intel Core i5 Branch Prediction Analysis and Results ............................................................61 
8.5 Atom Processor Analysis ............................................................................................................61 
CHAPTER 9. CONCLUSIONS AND FUTURE WORK ............................................... 62 
9.1 Objectives Achieved....................................................................................................................62 
9.2 Conclusions ..................................................................................................................................62 
9.3 Future Work ...............................................................................................................................63 
APPENDIX A ......................................................................................................................... 65 
APPENDIX B ......................................................................................................................... 67 
BIBLIOGRAPHY .................................................................................................................. 69 
 
 
 
 
 
v 
  
 
List of Figures 
Figure 2.1: Impact of increasing the instruction issue rate on the frequency of conditional 
branches per issue (5). ............................................................................................................... 5 
Figure 2.2: 2-bit branch predictor ............................................................................................. 6 
Figure 2.3: Two level adaptive predictor .................................................................................. 7 
Figure 2.4: Local branch predictor (8) ...................................................................................... 8 
Figure 2.5: Global branch predictor (8) .................................................................................... 9 
Figure 2.6: Agree predictor..................................................................................................... 10 
Figure 2.7: hybrid prediction .................................................................................................. 11 
Figure 3.1: Intel Nehalem Pipeline structure, Source: Real World Tech(17) ........................ 17 
Figure 4.1: Example - Assembly Level Analysis ................................................................... 22 
Figure 4.2: Implementation Outline ....................................................................................... 23 
Figure 5.1 BTB structure ........................................................................................................ 25 
Figure 5.2 Flow Diagram: Branch Prediction Analysis - ARM ............................................. 26 
Figure 5.3 BTB Capacity test.................................................................................................. 27 
Figure 5.4 BTB tests ............................................................................................................... 29 
Figure 5.5 MSB tag analysis flow........................................................................................... 30 
Figure 5.6 Summary : BTB structure ...................................................................................... 34 
Figure 6.1 General BTB Structure .......................................................................................... 35 
Figure 6.2 Expected results for 4-Way BTB structure with 1024 entries ............................... 36 
Figure 6.3 Microbenchmark - BTB capacity test example with 128 branches ....................... 37 
Figure 6.4 BTB capacity test: branches 128 to 1024. ............................................................. 39 
Figure 6.5 BTB capacity test: branches = 2048 and 4096 ...................................................... 40 
Figure 6.6 BTB capacity test with 8192 branches .................................................................. 40 
Figure 6.7: Overall BTB Capacity Analysis ........................................................................... 41 
Figure 6.8: set associative structure analysis .......................................................................... 42 
Figure 6.9: Results: set associative analysis ........................................................................... 43 
Figure 6.10: Algorithm to determine the msb index bit ......................................................... 43 
Figure 6.11: Results: BTB msb index bit analysis ................................................................. 44 
Figure 6.12: micro benchmark to analyse lsb index bit .......................................................... 45 
vi 
  
 
Figure 6.13: Result: lsb index bit analysis .............................................................................. 45 
Figure 6.14: indexing bits conversion function ...................................................................... 46 
Figure 6.15: Results: Tag MSB bit analysis ........................................................................... 46 
Figure 7.1: Loop predictor general structure .......................................................................... 48 
Figure 7.2: Counter Length test flow ...................................................................................... 49 
Figure 7.3: micro benchmark - loop counter analysis. ........................................................... 50 
Figure 7.4: Results: Loop counter analysis............................................................................. 50 
Figure 7.5: structure of loop capacity test .............................................................................. 51 
Figure 7.6: Micro benchmark: loop capacity test ................................................................... 52 
Figure 7.7: loop capacity analysis – Results ........................................................................... 53 
Figure 7.8: loop MSB bit test results ...................................................................................... 54 
Figure 7.9:loop LSB bit test results ........................................................................................ 55 
Figure 7.10: loop set associative test results ........................................................................... 55 
Figure 7.11: loop tag msb bit test results ................................................................................ 56 
Figure 7.12: micro benchmark to analyse relationship between BTB and loop predictor ..... 57 
Figure 8.1: Basic Implementation Block Diagram ................................................................. 59 
Figure 8.2: Automatic Analyser output: BTB structure ......................................................... 60 
Figure 8.3: Automatic Analyser output: Loop predictor structure ......................................... 60 
 
 
 
 
 
 
 
 
 
 
 
vii 
  
 
List of Tables 
Table 2-1: average branch distance and average branch ratio for different SPEC standards (5)
 ................................................................................................................................................... 4 
Table 5-1 Results collected with Branches = 64 ..................................................................... 28 
Table 5-2 Results collected with Branches = 128 ................................................................... 28 
Table 5-3 Results collected with Branches = 256 ................................................................... 29 
Table 5-4 Tag MSB bit analysis ............................................................................................. 31 
Table 5-5 2-bit saturation counter tests ................................................................................... 32 
Table 5-6 2-bit saturation counter tests ................................................................................... 33 
Table 6-1 Branch events used in analysis ............................................................................... 38 
Table 6-2 BTB Capacity test with branches = 128 ................................................................. 38 
Table 6-3: Results: 'not taken' branch analysis ....................................................................... 41 
Table 7-1: loop capacity results with distance = 16 ................................................................ 53 
 
 
 
 
 
 
 
 
 
 
viii 
  
 
Chapter 1.                                                         
INTRODUCTION 
1.1 Aims and Objectives 
The objectives of this project are as follows:  
? Analyse and Study the branch prediction structure of various modern computer 
architectures. 
? Decode the branch prediction structure of ARM processors.  
? Develop algorithms to aid in determining the branch prediction structure of Intel 
Nehalem architecture and reveal its organisation details.  
? Develop an automated analyser that takes the result data from the benchmark 
algorithms as input, generating the structure of the underlying branch predictor at its 
output. 
1.2 Outline 
The outline of the thesis is as follows: 
Chapter 1 provides an insight on the outline of the thesis and discusses the aims and 
objectives of the project and also talks about the motivation to carry out the work.  
Chapter 2 provides a brief introduction to branch prediction, the importance in modern 
architectures and different types of basic branch predictors currently used. It also includes 
discussion of the previous work done in this field. 
Chapter 3 talks about some of the industrial implemented branch predictors, specifically in 
ARM and Intel processors. 
Chapter 4 provides information about the tools and environment settings. It also briefly 
discusses the configuration and parameters of the tools used. 
Chapter 5 deals with the work done on decoding the branch prediction structure of ARM 
processors, specifically about the developed micro benchmarks and the analysis of the 
obtained results. 
Chapter 6 covers with the work done on determining the organisation of the Branch Target 
Buffer (BTB) Prediction unit of Intel?s Nehalem architecture and talks about the algorithms 
developed to understand the underlying structure of the BTB. 
Chapter 7 describes the work done on decoding the structure of Loop Predictors and 
includes discussion on the developed set of micro benchmarks that reveal the structure of 
loop branch buffers. 
 
1 
  
 
Chapter 8 explains the automatic analyser which is implemented to automatically provide 
the structure of the underlying branch predictor unit depending on the results fed to the 
analyser. 
1.3  Motivation 
Most medium to high end processor architectures rely heavily on their underlying 
branch prediction unit to utilize all its resources and achieve high performance. Most of the 
modern processor architectures implement deep pipeline levels with many parallel units in 
the architecture.  The performance of these units greatly relies on efficiency of the branch 
predictor unit.(1) 
Intel?s Nehalem architecture includes branch prediction units that are amongst the 
most advanced branch prediction units implemented. In the thesis, we intend to develop a set 
of micro benchmarks to understand the underlying branch prediction architecture.  
The developed algorithms and the automated analyser have great potential to benefit 
the industry and academicia in several ways: 
1.3.1 Architecture aware compilers  
Knowledge of the underlying branch prediction structure greatly enhances the 
performance of an architecture aware compiler. Study by (2) reveals that the Intel C++ 
compiler outperforms the Microsoft VC++ compiler for SPEC CPU200 benchmarks. This 
suggests that understanding underlying micro architecture features such as branch prediction 
structures greatly helps in improving the performance of software applications. 
1.3.2 Branch predictor design verification 
Ever increasing processor complexity and strict time to market constraints make the 
verification of the design in the first place very critical. Very often, architects tend to make 
changes in the implemented design to satisfy the power, performance and size constraints. 
Hence it is necessary that the changes are thoroughly tested before releasing. With tight 
constraints on time, often small micro benchmarks targeting a particular structure of the 
branch predictor structure become indispensible. Thus the automatic analyser and the micro 
benchmarks developed can be useful tool in a verification environment. 
1.3.3 Bridge gap between Academia and Industry  
Researchers often tend to concentrate on the accuracy of the branch predictor and 
rarely consider the area, power and timing constraints that are imposed by the chip industry. 
On the contrary designers in the industry strive hard to get efficient branch prediction 
implementations out of the available resources to meet the design constraints.  
Although we developed a set of micro benchmarks based on Intel?s Nehalem 
architecture, a slight modification to these benchmarks using a systematic approach can be 
used to determine the branch prediction structures of other architectures.                           
2 
  
 
Chapter 2.                                                          
BACKGROUND RESEARCH 
2.1 Introduction 
The section provides a brief introduction to branch prediction, the importance of it in 
modern computer architectures and the types of branch predictors commonly used. Later, we 
discuss previous research carried out in this field, specifically a paper on reverse engineering 
of branch prediction units used in Intel Pentium processors.(3)  
2.2 Branch Prediction 
In modern computer architectures the concept of pipelining is implemented which 
includes many pipeline stages, such as instruction fetch, decode, register allocation, µop 
reordering, multiple execution phases, load/store, and memory write back (1). Pipeline 
implementations are used as these enable the performance of different operations at same 
time and also help in efficient resource utilization, as all units are operated at any given time. 
The next instruction is fetched when the previous instruction is in the decode phase and so 
on. But the greatest hazard for the smooth operation of pipelines is the branch instruction. 
Once a branch instruction is encountered in the fetch phase of the pipeline, the address of the 
following instruction is not known until this branch instruction completes the execute phase 
of pipeline. This results in pipeline stalls and hence causes significant problems.  
 
To overcome pipeline stall, branch predictors are used in modern processors. Branch 
predictors guess whether a branch is likely to be taken or not and also where the target is 
likely to be if the branch is taken. Branch prediction deals with predicting the direction and 
target address of the branch before it reaches the execute phase of pipeline, thus helping next 
instructions to be fetched from correct path. Thus branches certainly have a great impact on 
performance in processors which implement more number of pipeline stages like Intel 
Nehalem.     
2.3 Importance 
Branch Predictors play a vital role in modern superscalar and instruction-level 
parallelism (ILP) processors. These processors have deeper pipelines and higher instruction 
issue rates, thus branch predictors with a high precision are mandatory. “It has been predicted 
that within a few years branch prediction becomes the most limiting factor in the 
performance of a processor, more so than the memory system ”. (4) Branch mis-prediction 
causes heavy penalty resulting in complete pipeline flushing and re-fetching of instructions 
from the correct location.    
 
3 
  
 
Sophisticated branch predictors are developed by designers to greatly reduce the 
frequency of mis-predictions in complex computer architectures with deep pipelines. Most of 
the processors use both static and dynamic branch predictors in their architecture to predict 
the outcome of a branch. The most commonly used static prediction is that all backward 
branches are predicted as „taken? while forward branches are predicted as „not taken?. The 
most commonly used dynamic branch predictor is predicting the outcome of current branch 
based on its previous outcomes (its history). 
 
“Even with generous resource allocation and no limit on the amount of state reached 
in one cycle, branch prediction is expected to create the most limiting bottleneck in future 
processors ” (4). 
2.3.1 Performance Impact 
Table 2-1 shows the average branch distance and average branch ratio of some of the 
SPEC benchmark programs. The table is grouped into two types depending upon the type of 
operation carried out. The top half of the table gives details of the general purpose (integer) 
benchmark programs while the bottom half gives the details of the scientific (floating point) 
benchmark programs. It can be observed that the average branch distance in general purpose 
programs and scientific programs varies greatly. It is also clear that there are more branches 
in general purpose programs compared to scientific programs.   
The average distance between branches in general programs is 4.6 instructions, while 
in scientific programs it is 9.2 instructions. This suggests that in general purpose programs 
th th th th
every 4 - 6 instruction can be a conditional branch instruction. In contrast, every 9 – 15 
instruction is a conditional branch instruction in scientific programs. 
Program Type Average branch Average branch 
distance ratio 
Eqntott General Purpose 2.86 35.0 
Espresso 4.81 20.8 
Li 6.05 16.5 
Average  4.57 21.9 
Doduc 10.59 9.4 
Scientific 
Matrix 3000 5.05 19.8 
Nasa 7 10.72 9.3 
Spice 2g6 3.27 30.6 
Tomcat 16.28 6 
Average  9.18 10.9 
Table 2-1: average branch distance and average branch ratio for different SPEC standards (5) 
Superscalar and ILP processors boost performance by executing more and more 
instructions in parallel. But as the number of instructions executed in each cycle increases the 
probability of encountering a branch instruction also increases and thus limits the 
performance of the superscalar or ILP. For example consider a general purpose code in which 
on an average every sixth instruction is a branch instruction as shown in Figure 2.1. Observe 
that if the issue rate is only two instructions per cycle then on average every third issue 
contains a conditional branch. Now consider if the issue rate is increased to three, then every 
second issue contains a conditional branch. The situation gets worse as the issue rate is 
4 
  
 
increased. For instance if the issue rate is increased to six then every issue will contain a 
branch instruction and this greatly degrades the performance of the processor and even 
suppresses the advantage of having many execution units and executing more instructions in 
parallel.  
Thus from the above example it is clear that predicting the outcome of unresolved 
conditional branches becomes an important task to achieve high performance. Significant 
importance is given to the branch prediction unit in the architecture of a processor as it plays 
a vital role to determine the performance of the processor. The next section gives insight to 
some of the simple and most commonly used branch prediction techniques. 
 
   
JC JC JC 
 
Scalar issue 
 
 
JC JC JC 
 
With 2 instructions/issue 
 
 
JC 
JC JC 
 
Superscalar issue 
With 3 instructions/issue 
Or VLIW issue 
 
 
JC 
JC JC 
 
With 6 instructions/issue 
 
JC – Conditional Branch 
 
t 
 
Figure 2.1: Impact of increasing the instruction issue rate on the frequency of conditional branches per 
issue (5). 
2.4 Branch Prediction Techniques 
On encountering the conditional jump, the branch prediction unit predicts the following: 
? The target branch address. 
? Whether the conditional jump will be taken or not. 
The basic kinds of branch predictions used are: 
? Fixed prediction: here the prediction is always the same, either always „taken? or 
always „not taken?. Also called „one outcome guess?. 
5 
  
 
? True Prediction: also called „two outcome guess?, the prediction can be either  „taken? 
or „not taken? and is divided into two types, namely: 
o  Static Prediction: here predictions are made based on the object code. 
o  Dynamic Prediction: here the prediction is made based on the execution history. 
2.4.1 Static Branch Prediction 
Here the prediction is made on particular attributes of the object code. The following 
are the most commonly used static branch prediction methods: 
? Opcode-based prediction: The prediction of a branch depends on the opcode of the 
instruction. The branch can be „taken? for certain opcodes and „not taken? for others. 
? Displacement-based prediction: The branch is predicted based on the displacement of 
the branch target address (BTA). If the BTA is less than zero (i.e. a backwards 
branch) then it is assumed to be „taken?, else it is a forwards branch and assumed to be 
„not taken?. This method is very popular among static branch prediction. 
? Compiler-directed prediction: As the name indicates, the prediction is made by the 
compiler itself based on the control construct compiled and is indicated by either 
setting or clearing a „predict? bit while encoding the branch instruction.  
2.4.2 Dynamic Branch Prediction 
In this scheme the branch history is used to predict the branch direction and target 
branch address. The following are the different types of dynamic branch prediction 
techniques.  
2.4.2.1 2-bit Dynamic Branch Prediction Technique 
In a 2-bit dynamic branch prediction, two bits are used to maintain the last occurrence 
of the particular branch and as it makes use of 2-bits there are four possible states - strongly 
taken, weakly taken, weakly not taken and strongly not taken. The state diagram for a 2-bit 
dynamic branch prediction is as shown in Figure 2.2: 
 
ANT 
ANT 
ANT 
 
AT ANT 
 
Strongly  Weakly   Strongly 
Weakly 
not 
taken taken taken  not taken 
 
    
 
00 
11 10 01 
AT AT 
AT 
 
 
Prediction: Not Taken 
Prediction: Taken  
 
AT: Branch has actually been taken 
 AT: Branch has actually not been taken 
Figure 2.2: 2-bit branch predictor 
6 
  
 
The branch is predicted based on the status stored in the counter as follows. If the 
state is either „strongly taken? or „weakly taken?, then the branch is predicted as „taken? else if 
the state is either „weakly not taken? or „strongly not taken? then the branch is predicted as 
„not taken?. After the conditional branch is resolved, the status is updated as a two-bit 
saturating counter in the history table.  
The advantage of this branch prediction is it performs well for a branch whose target 
address is the same most of the time, as is the case for many conditional branches. But its 
performance degrades if the branch target address changes too often (6). 
2.4.2.2 Two Level Adaptive Predictor 
A two level adaptive predictor maintains the history of the last n occurrences of the 
branch in a special cache called the pattern history table, as illustrated in Figure 2.3. Since 
n
there are n occurrences this table consists of 2 history patterns and each entry internally is a 
saturating counter as was illustrated in section 2.4.2.1.  
 
 
Pattern history table 
 
 
     
 
Prediction 
    
Branch history 
 
     
   
0010 
 
 
 
   
 
 
 
Figure 2.3: Two level adaptive predictor 
Now, consider n=2. If n=2 then the branch history is a two bit entry and 
n
corresponding to 2 = four different binary values („00?, „01?, „10? and „11?, where „0? ? „not 
taken? and „1? ? „taken?). Each entry in the pattern history table is a 2-bit saturating counter 
as discussed in Figure 2.2. The two bit value of each branch history register chooses which 
particular entry of the available four entries in the pattern history table is to be considered. If 
the branch history register is „00? then the first saturating counter in the pattern history table 
is used and if the branch history register contains ?11? then the last (fourth) entry from the 
pattern history table is used. 
The general rule for a two-level adaptive predictor with an n-bit branch history register is as 
follows: 
Any repetitive pattern with a period of n+1 or less can be predicted perfectly after a warm-up 
time no longer than three periods. A repetitive pattern with a period p higher than n+1 and 
7 
  
 
less than or equal to 2n can be predicted perfectly if all the p n-bit sub-sequences are 
different (7). 
 
This method overcomes the cons of two-bit dynamic branch prediction techniques and 
quickly learns to predict the outcome of an arbitrary repetitive branch pattern.  
2.4.2.3 Local Branch Prediction 
A local branch predictor is the extension of the previously illustrated adaptive 
predictor. It makes use of a separate history buffer register and a pattern history table for each 
of the conditional jump instructions. Its implementation is illustrated in Figure 2.4. It predicts 
the outcome of a branch depending upon the previous „n? outcomes of the branch instruction.  
The Intel Pentium II and Pentium III processors use local branch predictors to predict 
the outcome of a conditional jump. They implement local branch predictors with local 4-bit 
history and a 16-entry local pattern history table for each conditional jump. 
 
 
Figure 2.4: Local branch predictor (8) 
 
 
2.4.2.4 Global Branch Prediction 
In section 2.4.2.2, we discussed a two-level branch predictor. We note that it uses an 
n
„n? bit history register and a „2 ? pattern history table for each conditional branch. It should be 
noted that there is a practical limit as to how big the number of history bits „n? can be, as the 
cache size requirement increases dramatically with „n?.  One way to overcome this will be to 
use a shared branch history register and a shared pattern history table among all the branches. 
This arrangement leads to global branch prediction algorithm.  
 
 
8 
  
 
A global two-level branch predictor is shown in . This implementation maintains a 
single branch history register for all the conditional branches/jumps. It predicts the outcome 
of the branch based on the pattern of the outcome of the preceding „n? branches. The 
advantage of this prediction is that it uses the correlation between branches to predict the 
outcome. But the performance of this predictor is poor if the different branches are not 
correlated.   
 
 
 
 
Figure 2.5: Global branch predictor (8) 
 
 
This method has been implemented in processors such as some of AMD?s 64 bit 
processors (n=8) and P4E processor (n=16) (6). 
2.4.2.5 The Agree Predictor 
The disadvantage of using global branch predictors is that they make use of the 
correlation between branches and even the branches with no correlation share the same global 
pattern history table. This problem can be reduced by storing an extra bit called a „biasing bit? 
in the BTB or instruction cache which can be used to indicate whether the branch is „mostly 
taken? or „mostly not taken?. In an agree predictor, instead of indicating the direction of a 
branch, the pattern history table now indicates whether the branch will be „taken? or „not 
taken? in the direction of the „biasing bit?. This scheme effectively reduces the negative 
interference if a proper biasing bit is used.  
 
An implementation of an agree predictor is as shown in Figure 2.6. Each branch 
implements a local predictor using a saturating counter and the indexing function is 
implemented by using an XOR function. The global branch history table is indexed by the 
global branch history and branch address, and indicates whether the branch is predicted to 
agree or disagree with the output of the local predictor (9).   
 
 
 
 
 
 
 
9 
  
 
  
 
 
Global Pattern 
 
history table 
 
 
 
Global Branch 
    
 
history 
 
0110     
 
 
     
Agree/ 
 
Indexing 
   
Disagree 
 function 
  
 
Branch 
XOR 
Prediction 
Address 
 
    
 
 
 
Local predictor 
Taken/ 
 
Not-taken 
    
 
 
Figure 2.6: Agree predictor 
2.4.2.6 Loop Predictor 
Loop predictors are used to predict loop-delimiting branch instructions. For example 
consider a loop with „N? iterations in it. A conditional branch inside a loop structure, when 
placed at the bottom of the loop will be „taken? N-1 times and will be „not taken? the last 
time. While the same conditional branch instruction when placed at the top of the loop will be 
„not taken? N-1 times and will be „taken? the last time. Such a conditional branch which goes 
in one direction for many times and then the other way is termed to show loop behaviour. 
Such a branch can be easily predicted by using a simple counter. A loop predictor is a type of 
hybrid predictor where a meta-predictor detects whether the particular branch exhibits loop 
behaviour. 
Intel?s Pentium M and Core2 processors use a loop predictor with a loop counter of 6 
6
bits. Any loops with a loop iteration count of less than 64 (=2 ) are predicted perfectly (6). 
2.4.2.7 Indirect Branch Predictor 
With more and more applications being developed using object oriented code, the 
correct prediction of indirect branches is becoming crucial. C++ code can generate indirect 
jumps by using function pointers, virtual function or by calls with switch statements. An 
indirect jump or call is a branch instruction that has more than two possible target addresses. 
Normally, the target branch address is part of the opcode, but in indirect branches it is 
specified by using a value in a register, a memory variable or an indexed pointer as the 
destination of the jump or call instruction. 
 
10 
  
 
Normally in many processors the BTB is implemented such that only one entry is 
made for every indirect branch or call. This results in a jump being predicted to be always to 
the same branch target address as last time, which is incorrect. Thus, an indirect branch 
prediction should be implemented by assigning a new BTB entry for every new branch target 
address that is encountered. The branch history register and the pattern history table must be 
suitably modified to hold more than one bit of information for every branch in order to 
distinguish between more than two possible targets (10).   
 
Working of Branch target buffer (BTB): 
 
A branch target buffer (BTB) is a special cache which is used to store the branch 
address and the branch target address of a branch instruction. When a conditional branch is 
encountered for the first time, the branch target address is stored in the BTB and during 
subsequent executions of the same branch, the branch target address stored in the cache is 
retrieved to fetch the next instruction into the pipeline, although the actual target address is 
not calculated until the branch instruction has been resolved in the execution stage of the 
pipeline.   
2.4.2.8 Hybrid Predictor 
Researchers have shown that the most effective single scheme predictors use a large 
amount of branch history information and that two such predictors combined can outperform 
a single predictor at the same implementation cost (11). 
 
A hybrid predictor combines two or more different branch predictors, each selected 
for its ability to accurately predict a particular class of branch. Hybrid predictors make it 
advantageous to have more than one branch predictor in architecture. For example, most 
recent architectures have different branch mechanisms for indirect branches, loops, BTBs, 
return stacks etc.  
 
 
 
   
 
Predictor Predictor Predictor 
 
1 2 3 
 
 
 
 
 
 
 
Selection 
 
Mechanism 
 
 
 
Prediction 
 
 
 
Figure 2.7: hybrid prediction 
11 
  
 
2.4.2.9 Return stack buffer 
The return stack is a buffer that is used to store the return addresses of call 
instructions. Each time a call instruction is encountered, the corresponding return address is 
stored in the return stack. When a return instruction is encountered, the corresponding return 
address is popped back from the stack. Since it is possible that the same procedure might be 
called from different locations it is necessary to pair up the return address with the 
corresponding subroutine calls in order to maintain correctness. Return instructions are a 
special case of indirect branches.  
Unfortunately a return stack may be corrupted due to branch mis-prediction, an effect 
which is more likely to occur in deeper pipeline architectures. Inappropriate handling of this 
problem may seriously affect performance. Return stack corruption is overcome by recording 
the push and pop after any mis-predicted branch (12).  
Although this section gave an insight on common branch predictors, many different 
kinds of branch predictors do exist (13),(14). It is likely that even more sophisticated branch 
prediction methods will be implemented in the future if pipelines are extended further. 
 
2.5 Previous Work 
Reverse engineering of micro architectural features has been a topic that has 
generated intense discussion over the years. Early work done by Aleksandar Milenkovic and 
Milena Milenkovic(15) on „unveiling the structure and organisation of Intel branch 
predictors?, gives significant insight on the way to perform analysis of complex branch 
predictors. The paper mainly concentrated on Intel NetBurst architecture and the Intel P6 
architecture. Another paper by Vladimir Uzelac and Aleksandar Milenkovic (3) gives 
valuable insight on reverse engineering of the branch predictor unit of the Intel Pentium M. 
This paper mainly focuses on developing a set of microbenchmarks to decode the underlying 
structure of the branch prediction unit.  
In the Pentium Optimisation Manual (6), A. Fog describes the research work carried 
on analysing the branch predictors of various Intel and AMD architectures. In this section we 
discuss the contributions made by these three papers and reveal the importance of these 
papers for analysing the branch prediction unit of Intel?s Nehalem architecture.   
The paper by A.Milenkovic and M.Milenkovic(15) mainly focuses on the BTB component 
and the Outcome predictor component used in Intel?s Netburst and P6 architectures. The 
inferences from the paper are as follows: 
? BTB organisation (P6 architecture): 
1. The total size of BTB is 1024 entries. 
2. The BTB is organised as a 4-way set. Each set has 128 entries. 
3. The BTB cache is addressed (indexed) by the branch address bits [10:4]. 
4. The LSB bits [3:0] represent the offset.  
? Global predictor: It confirms that the P6 architecture does not include any global 
prediction component. 
 
 
12 
  
 
? Front-end BTB organisation (NetBurst architecture) :  
1. The total size of BTB is 4096 entries.  
2. The BTB is organised as a 4-way set. Each set has 1024 entries. 
3. The BTB cache is addressed (indexed) by the branch address bits [13:4]. 
4. The LSB bits [3:0] represent the offset.  
? Global predictor: It confirms that the NetBurst architecture has a global prediction 
component with 16 global history bits. 
 
The research work carried by A.Fog(6) reveals some important information about the 
organisation of the branch predictor structures used in Intel, AMD and VIA CPUs. Although 
it gives a good insight of most of the industrial branch predictors it does not show the exact 
details of how the experiments were carried out. It also mentions very little about the Intel 
Nehalem branch predictor structure. The research by A.Fog done on the Intel Nehalem and 
Intel Atom architectures is briefly discussed in sections 3.2.1 and 3.2.2. In this thesis we 
intend to verify some of the findings of A.Fog about the Nehalem architecture and also to 
extend these methods to reveal the complete structure of the branch predictor used. 
Uzelac and Milenkovic (3) have published the complete branch predictor structure of 
the Pentium M processor architecture and have developed a number of micro-benchmarks to 
reveal the underlying branch prediction structure. The following are some of the important 
results of their experiments: 
? The BTB is organised as a 4 way set associative structure with 512 entries in each set 
with a total number of 2048 entries. The BTB is indexed by the branch address bit 
[12:4] and the branch address bits [21:13] are used as a tag field. 
? It implements an outcome predictor with a 4096 entry bimodal predictor.  
? It also implements a loop predictor with total of 128 entries organised as a 2 way set 
associative cache indexed by branch address bits [9:4]. 
? A 4-way global predictor is incorporated with 2048 entries. 
We intend to carry out our study of Intel Nehalem?s branch prediction structure in a 
similar way as carried in (15) and (3), as the branch prediction unit of Nehalem is a derivative 
of that in the Intel Pentium M. We predict that the branch prediction structure of Nehalem is 
an extended version of its previous architecture. We intend to develop some of the algorithms 
that were used in the paper by Uzelac and Milenkovic (3) and build on these algorithms as 
required.  
In this thesis we are mainly concentrating on two types of branch prediction structures: 
 1. Branch Target Buffer (BTB) Predictors. 
 2. Loop predictors. 
 
 
13 
  
 
Chapter 3.                                                                          
INDUSTRIAL BRANCH PREDICTORS 
This section introduces some of the branch predictors implemented in real processors. 
It describes the branch predictors that are published by the vendor or revealed by some 
research carried out previously. We cover the types of branch predictors that are implemented 
in ARM and Intel Processors (Intel Atom and Intel Nehalem architecture). 
3.1 ARM PROCESSOR 
ARM processors implement relatively simple branch predictor structures compared to 
Intel processors, for example. Following are the details of the branch predictors that are used 
in different families of ARM processors. 
3.1.1 ARM 7 
The ARM 7 series ARM7TDMI and ARM7EJ-S processors do not implement any 
branch prediction mechanism. These processors implement a simple three stage pipeline 
architecture with no pre-fetch unit, hence the target of the branch address is not known until 
execute stage of the pipeline, at which time it is known whether the branch is „taken? or „not 
taken?. 
In these processors all the branches are predicted as „not taken? and the pipeline is 
filled with the instructions that follow the branch instruction.  
3.1.2 ARM 8 
The ARM 8 series ARM810 processor implements a four stage pipeline architecture 
with a pre-fetch unit. Due to the presence of pre-fetch unit the branch instructions are 
detected before they enter the core, hence it is possible to implement a branch prediction 
mechanism.  
ARM 8 implements a simple static branch prediction mechanism. All the forward 
branching branches are predicted as „not taken? and all the backward branching branches are 
predicted as „taken?. This results in the reduction of average branch Cycles Per Instruction 
(CPI) and thus improves the processor?s performance.    
3.1.3 ARM 9 
The ARM 9 series ARM9TDMI, ARM926EJ-S and ARM946EJ-S processors do not 
implement any branch prediction mechanism. These processors implement a five stage 
pipeline architecture with no pre-fetch unit, hence the target of the branch address is not 
known until execute stage of the pipeline, at which time it is known whether the branch is 
„taken? or „not taken?. 
14 
  
 
In these processors all the branches are predicted as „not taken? and the pipeline is 
filled with the instructions that follow the branch instruction. 
3.1.4 ARM 11 
The ARM 11 series ARM1136 and ARM11 MPcore processors have an 8-stage 
pipeline architecture and implement a branch prediction unit. The program flow prediction is 
carried out as follows: 
? The Core implements Static Branch Prediction and a Return Stack. 
? The Pre-fetch Unit implements Dynamic Branch Prediction. 
Dynamic branch prediction 
 
ARM1136JF-S makes use of a dynamic first level branch predictor. The dynamic 
branch predictor is implemented by using a single Branch Target Address Cache (BTAC) and 
includes a 128 entry directly mapped cache structure which is used to store the branch 
address, branch target address and prediction of whether the branch is „taken? or „not taken?. 
Dynamic branch prediction is done by using the two bit saturating counter inside the BTAC. 
Once a branch is allocated in the BTAC, it is only evicted during a capacity clash or due to 
any address mapping conflicts.   
 
A branch entry is allocated into the BTAC after the resolution of the branch in the 
execute stage of the pipeline. Whenever a branch is encountered, the BTAC is searched and if 
a BTAC hit occurs then the branch target address stored in the BTAC is used as a program 
counter to fetch the next instruction. If a BTAC hit occurs then the branch is predicted with a 
zero cycle delay.  
 
Static branch prediction 
 
ARM1136JF-S implements a second level of branch prediction called static branch 
prediction, where all unconditional branches are predicted as always „taken?. All conditional 
backward branches are predicted as always „taken? and conditional forward branches are 
predicted as always „not taken?. All the branch instructions that are encountered for the very 
first time are predicted by using this static branch prediction scheme. The branches that are 
evicted from the BTB due to a capacity clash or address conflict are also predicted using the 
static branch predictor. Thus the first time any branch instruction is met it is predicted with 
the static branch predictor before subsequently being handled by the dynamic branch 
predictor. However the static branch prediction can be enabled or disabled by setting a bit in 
a configuration register.  
 
Return stack 
 
The return stack is implemented as a three-entry circular buffer, which is used to 
predict procedure calls and unconditional procedure returns. 
 
“Using a combination of dynamic and static branch prediction we can typically 
correctly predict whether the branch will be taken about 85% of the time. If 
the branch prediction fails, the core pipeline will need to be refilled and the current 
instruction pipeline flushed”. (16) 
15 
  
 
It can be inferred that the ARM cores use fairly traditional branch predictors. Hence 
in our project we began by developing algorithms to analyse the branch predictors of ARM 
cores.  
3.2 Branch Prediction Techniques - Intel 
3.2.1 Branch Prediction in Intel Atom 
The Intel Atom processor architecture makes use of a two level adaptive branch 
predictor with a global history table. The following details have been found on the Intel Atom 
architecture from the research done by Fog Agner(6). They have found that it uses a BTB 
with 128 entries, a branch history register with 12 bits and a pattern history table with 4096 
entries. The pattern history table entries are shared between threads. And, conditional „taken? 
and „never taken? branches are entered into the global history table while unconditional 
branches are treated separately and do not have entries in the history table.  
 
Misprediction penalty 
 
The BTB stores the branch target address and in Intel Atom the BTB is much smaller 
than in other architectures. Thus it may happen that there might be a valid entry in the pattern 
history table for a branch but due to no entry in the BTB (a BTB miss), the branch is not 
predicted to completion. This results in a penalty of approximately 7 clock cycles. If a branch 
is completely mis-predicted then the penalty is 13 clock cycles. It is most likely that there is 
no separate branch predictor to predict the outcome of indirect branches, but instead indirect 
branches in Atom are predicted to jump to the same target as last time. It has a return stack 
buffer (RSB) with 8 entries (6). 
3.2.2 Branch Prediction in Intel Nehalem Architecture 
The Nehalem architecture is designed to be modular to target servers and high 
performance workstations. In this sub section we discuss the branch prediction architecture 
that is incorporated in this architecture.  
3.2.2.1 Branch Prediction Unit 
Intel has not published much on the branch prediction mechanism used in the 
Nehalem architecture. There is very little literature that gives an insight on what might be the 
branch prediction mechanism used in this architecture. Following are the details of the 
possible branch prediction mechanisms used in the Nehalem micro architecture.  
 
Pattern recognition for conditional jumps 
 
As it is clear that Nehalem has a long mis-prediction delay, significant effort has been 
dedicated to develop an improved branch predictor. Below are the salient features of the 
branch prediction mechanism used:  
? A hybrid branch predictor has been implemented consisting of a two-level branch 
predictor and a separate loop predictor.  
? It has a mechanism to predict indirect jumps and indirect loops.  
 
 
16 
  
 
1
Figure 3.1:Intel Nehalem Pipeline structure, Source: Real World Tech(17) 
 
 
Non loop behaviour branch prediction 
 
A two level predictor is used to predict branches which do not show loop behaviour. It 
uses an 18-bit global history buffer with an associated pattern history table. The efficiency of 
the prediction of the branches with particular repetitive patterns depends on the number of 
jumps in the loop. It is revealed that Nehalem provides two 18-bit global history buffers: the 
first one includes all conditional and unconditional branches but excluding never taken 
branches. The second buffer includes only the important branches such as conditional 
branches.     
                                                 
1
  Figure is not of high quality as the source is a webpage. 
17 
  
 
 
Return Stack Buffer 
 
The return stack buffer (RSB) is used to store the return address of procedure calls. 
However as seen in section 2.4.2.9, the return stack buffer may get corrupted when a branch 
predictor speculates a wrong path or due to stack overflow. Under these circumstances the 
Nehalem architecture renames the RSB which ensures that the RSB does not overflow while 
at the same time making sure that the mis-speculation does not corrupt the RSB. Also 
Nehalem implements a separate RSB for each of the threads ensuring no cross-
contamination. (18) 
 
Misprediction penalty 
 
The mis-prediction penalty usually depends on the length of the pipeline used in the 
architecture. Intel Nehalem uses a longer pipeline than its predecessor the Core2. In fact the 
mis-prediction penalty in Nehalem is 17 clock cycles, which is substantial. The complex 
pipeline structure of Intel Nehalem is shown in Figure 3.1. 
     
18 
  
 
Chapter 4.                                                                                  
TOOLS AND ENVIRONMENT SETTINGS  
This chapter focuses on various tools used to setup the environment for the 
experiments to be conducted. The performance monitor register subsection describes the 
event count registers that were used during the analysis. We also discuss the hardware events 
that were used to extract the branch related information such as branch misprediction 
percentages and the number of branches executed.  
4.1 Tools   
Following are the set of tools that are used in this project.  
4.1.1 ARM Workbench IDE v4.0 and RVDS 
? The ARM Workbench is an Integrated Development Environment (IDE) which can be 
used to create, debug, profile, flash and trace C/C++ projects for all ARM processor 
based targets. 
? The RVDS 4.1 Professional IDE comes with an in-built ARM profiler which enables 
non-intrusive analysis of embedded software performance over long runs. It can 
gather profile information for code running over minutes, hours or even days. It can 
operate at a frequency of up to 400MHz.    
? It has got a built-in fully featured assembler and C/C++ editor, built-in syntax 
highlighting and provides assembler files with customizable formatting of code so that 
it is readable.  
The ARM Profiler provides instruction coverage, code coverage and also branch 
coverage. This information can be used to test the quality level and the effectiveness of the 
implementation of the embedded software. The Profiler also allows combining multiple 
analysis runs into a single report. The branch coverage information provides details of the 
total number of branch instructions in the code, the number of branch mis-predictions, etc. 
(19) 
The RVDS tool was used to extract the branch target addresses and branch addresses. 
This information was used to analyse the behaviour of the branches for various different sets 
of micro-benchmarks.   
RVDS was also used to monitor the „performance monitor control registers? contents 
which included the events count register such as: 
? Cycle Count Register (CCNT) 
? Count Register 0 (PMN0) 
? Count Register 1 (PMN1) 
19 
  
 
The Count Registers were configured to count the following events: 
? Branch Instruction Executed. 
? Branch Instruction Mis-predicted. 
4.1.2 Intel Vtune 
? Intel provides a tool called the Intel VTune Amplifier XE that can be used for 
performance analysis and tuning of the system and software applications. It has 
various different tools integrated into its environment and provides a user interface for 
collecting performance related data. 
? The utility provides different analysis techniques allowing the user to add one or more 
tasks and also specify the type of performance data to be collected. 
? Any analysis type provided by VTune is based on one of the following data 
collections types:  
o Hardware event-based sampling collection. 
o User-mode sampling and tracing collection. 
“The VTune Amplifier XE also enables you to create custom analysis types based on one of 
these collection types ”.(20) 
? Algorithm analysis is the analysis type that can be used to tune software. It helps to 
improve the performance of an application by providing an environment to run 
various analyses and collect data to decide the best algorithm. 
o Algorithm analysis includes the following analysis types: 
? Lightweight Hotspots 
? Hotspots 
? Concurrency 
? Locks and Waits 
? Advanced Hardware Level Analysis: This analysis is particularly targeted to Intel Core 
2 processor family, Intel Nehalem micro-architecture and the Intel next generation 
Sandy Bridge micro-architecture. Data collection is by event-based sampling.     
o Following are the Intel micro-architecture code name Nehalem analysis types: 
? General Exploration 
? Cycles and uOps 
? Front End Investigation 
? Memory Access 
The Intel Vtune?s „Custom Analysis? type is used to get access to hardware event 
counters. The „LightWeight Hotspot? Analysis is carried out under the „Custom Analysis?. 
The following are the branch-related hardware events that are provided by the „Intel Core 
Processor Family?: 
20 
 